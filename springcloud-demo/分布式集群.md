# 分布式集群

[TOC]

## 理论基础
### ACID&BASE&CAP
[架构师都该懂的CAP定理](https://www.cnblogs.com/one12138/p/13341366.html)
[关于ACID，BASE和CAP定理的探究](https://www.cnblogs.com/misterchaos/p/13549341.html)
```markdown
ACID是传统关系型数据库事务的四个特性：
    原子性(Atomicity): 指所有在事务中的操作要么都成功，要么都不成功，所有的操作都不可分割，没有中间状态。一旦某一步执行失败，就会全部回滚到初始状态。
    一致性(Consistency): 在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等
    隔离性(Isolation)：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
    事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。
    持久性(Durability)：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
    具有ACID特性的数据库系统，可以保证在写入或更新数据时，事务是正确可靠的。ACID的目标是保证数据的正确性和一致性。
BASE的思想是，为了提高系统的可用性，允许在某些时候，某个节点返回的不是最新的数据，但是在一段时间之后，系统中的数据最终会达到一致。
    这种做法可以在系统访问高峰时牺牲一定的一致性，保证可用性，在高峰过后又恢复数据的一致性。
    基本可用（Basically Available）：分布式系统在出现不可预知故障的时候，允许损失部分可用性
    软状态（Soft State）：允许系统中的数据存在中间状态，即不同节点上的数据不一致
    最终一致性（Eventually Consistent）：软状态不能一直持续，在一定期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性
CAP定理:在一个跨区域网络连接，共享数据的分布式系统中，一致性（Consistency），可用性（Availability）和分区容错性（Partition Tolerance）
    由于分布式系统必须保证分区容错性，所以只能选择AP原则或者CP原,这三个约束属性最终只能同时满足二个。
    一致性（Consistency）：客户端进行读操作得到的数据永远是最近一次写入的数据，要求了对数据读写的强一致性。
    可用性（Availability）：客户端的请求在限定时间内总能从非故障的系统节点得到正常的响应，其中不能有超时，不能出错如502之类。
    分区容错性（Partition tolerance）：就是出现网络分区现象，即节点间无法正常通信，数据同步出现延时等情况时，系统仍能继续提供服务。
对比Eureka和Zookeeper在CAP中的选择
    CP原则：放弃高可用性，实现强一致性。（两阶段提交，三阶段提交）如分布式数据库、分布式锁，服务注册中心Zookeeper,Consul,Mongodb
    AP原则：相当于放弃了强一致性，实现最终的一致。如DNS，服务注册中心Eureka
    Nacos：AP和CP两种模式都可以满足
```


## 分布式事务解决方案
[3天深入学习分布式事务应用及解决方案]( https://www.bilibili.com/video/BV1GJ411m73n )
[微服务架构的分布式事务控制解决方案]( https://www.bilibili.com/video/BV1Q4411y7ip )

[如何选择分布式事务解决方案？](http://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247496338&idx=1&sn=088c5980f84feb7133f83a0835d49bc9&chksm=e92acf9dde5d468bc9d88eefdd7ea89d58353541d85f79d5cd9b09c67fe06a8a61ca13320968&mpshare=1&scene=23&srcid=&sharer_sharetime=1590626960950&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)

[参考视频1：分布式事务解决方案](https://www.bilibili.com/video/av64323822)

[参考视频2：阿里分布式事务框架Seata原理解析](https://www.bilibili.com/video/av50531999)

[参考视频3：阿里如何解决分布式事务](https://www.bilibili.com/video/av40630844)

[分布式事务](https://www.cnblogs.com/xiaobingblog/p/11540341.html)

[SpringBoot的事物Transaction使用的教程](https://www.cnblogs.com/xuwujing/p/11184162.html)

[终于跑通分布式事务框架tcc-transaction的示例项目](https://www.cnblogs.com/bigdataZJ/p/tcc-transaction-sample.html)

[TCC 分布式事务](https://www.cnblogs.com/jajian/p/10014145.html)

[浅谈分布式事务与TX-LCN](https://www.cnblogs.com/tanshaoshenghao/p/11684727.html)
[五大分布式事务，你了解多少？](https://www.cnblogs.com/mingyueyy/p/13656330.html)
[分布式事务解决方案：TCC与最终一致](https://www.cnblogs.com/sw008/p/11054277.html)
[快速了解阿里微服务热门开源分布式事务框架——Seata](https://www.cnblogs.com/fengpinglangjingruma/p/13963902.html)
[阿里分布式事务seata入门（采坑）](https://www.cnblogs.com/sky-chen/p/11419942.html)
[Spring Cloud Alibaba | 微服务分布式事务之Seata](https://www.cnblogs.com/babycomeon/p/11504210.html)
[Spring Cloud同步场景分布式事务怎样做？试试Seata](https://www.cnblogs.com/zlt2000/p/11525417.html)
[SpringCloud系列之集成分布式事务Seata应用篇](https://www.cnblogs.com/chinaWu/p/13255200.html)

[我是如何基于二阶段递交及悲观锁实现分布式事务的](https://www.cnblogs.com/BaiCai/p/11184009.html)

## 集群
[参考资料：cyc2018大佬]
### 1. 负载均衡
```markdown
集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。
负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。
负载均衡器可以用来实现高可用以及伸缩性：
    高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
    伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。
负载均衡器运行过程包含两个部分：
    1. 根据负载均衡算法得到转发的节点；
    2. 进行转发。
```
#### 1.1 负载均衡算法
```markdown
1. 轮询（Round Robin）:轮询算法把每个请求轮流发送到每个服务器上。
    比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载
2. 加权轮询（Weighted Round Robbin）：加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。
3. 最少连接（least Connections）：最少连接算法就是将请求发送给当前最少连接数的服务器上。
    由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。
4. 加权最少连接（Weighted Least Connection）：在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。
5. 随机算法（Random）：把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。
6. 源地址哈希法 (IP Hash)：源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。
    可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）
```
#### 1.2 转发实现
```markdown
1. HTTP 重定向
HTTP重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的IP 址之后，将该地址写入HTTP重定向报文中，状态码为302。
客户端收到重定向报文之后，需要重新向服务器发起请求。
缺点：
    需要两次请求，因此访问延迟比较高；
    HTTP 负载均衡器处理能力有限，会限制集群的规模。
该负载均衡转发的缺点比较明显，实际场景中很少使用它。
2. DNS 域名解析
在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。
优点：
    DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。
缺点：
    由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。
大型网站基本使用了DNS做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器IP地址。
3. 反向代理服务器
反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。
在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部IP地址，而反向代理需要配置内部和外部两套IP地址。
优点：
    与其它功能集成在一起，部署简单。
缺点：
    所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。
4. 网络层
在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的IP地址，并修改请求数据包的目的IP地址，最后进行转发。
源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。
优点：
    在内核进程中进行处理，性能比较高。
缺点：
    和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。
5. 链路层
在链路层根据负载均衡算法计算源服务器的MAC地址，并修改请求数据包的目的MAC地址，并进行转发。通过配置源服务器的虚拟IP地址和负载均衡服务器的IP地址一致，
从而不需要修改IP地址就可以进行转发。也正因为IP地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。
这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。
这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux VirtualServer）。
```
### 2. 集群下的Session管理
[一口气说出 4 种分布式一致性 Session 实现方式，面试杠杠的~](https://www.cnblogs.com/goodAndyxublog/p/13327412.html)
```markdown
一个用户的Session信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，
由于服务器没有用户的Session信息，那么该用户就需要重新进行登录等操作。
Sticky Session:需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的Session存放在该服务器中。
               缺点：
               当服务器宕机时，将丢失该服务器上的所有 Session。
Session Replication:在服务器之间进行Session同步操作，每个服务器都有所有用户的Session信息，因此用户可以向任何一个服务器进行请求。
                缺点：
                占用过多内存；
                同步过程占用网络带宽以及服务器处理器时间。
Session Server:使用一个单独的服务器存储Session数据，可以使用传统的MySQL，也使用Redis 或者Memcached这种内存型数据库。
                优点：
                为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会
                话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。
                缺点：
                需要去实现存取 Session 的代码。
```
### [4.分布式系统中session一致性问题](https://www.cnblogs.com/jajian/p/10962989.html)
#### 问题存在
```markdown
在单机系统中，用户登陆之后，服务端会保存用户的会话信息，只要用户不退出重新登陆，在一段时间内用户可以一直访问该网站，无需重复登陆。
用户的信息存在服务端的session中，session中可以存放服务端需要的一些用户信息，例如用户ID，所属公司companyId，所属部门deptId等等。
当下流行的微服务。虽然在用户端看来系统仍然是一个整体，但在技术端来说业务则被拆分成多个模块，各个模块之间相互独立，甚至不在同一台物理机器上，模块之间通过RPC进行通信。
```
#### 问题解决:从以下几个方面想到解决的方法
```markdown
每个服务端存储一份，通过同步的方式保证一致性，但是这种方式有个很明显的缺点：session的同步需要数据传输，占内网带宽，有时延，
网络不稳定的时候会造成部分系统同步延迟，那么就不能保证 ession一致性。而且所有服务端都包含所有session数据，数据量受内存限制，无法水平扩展。
1.在用户首次登陆的时候将用户信息放到 Token并缓存到 Redis 中，同时设置一个过期时间。
2.可以定义一个拦截器 SessionInterceptor，当访问web接口的时候检验用户的token信息，判断用户是否登陆，
    未登录的情况下一些业务接口是无法访问的，以及在登陆的情况下拿到我们需要的用户信息，如userId。
以上实现方式简单易用，而且Redis 在分布式系统中的使用率也很高，所以无需额外的技术引入。
可以支持水平扩展，数据库或缓存水平切分即可，服务端重启或者扩容都不会有session丢失的情况发生。
```
## 分布式
【分布式系统】[分布式系统](https://www.cnblogs.com/Zachary-Fan/p/distributedsystems.html)
[随笔分类 - 【分布式】-- 分库分表](https://www.cnblogs.com/qdhxhz/category/1558200.html)

[这三年被分布式坑惨了，曝光十大坑](https://www.cnblogs.com/jackson0714/p/fenbushi.html)
[自己动手实现分布式任务调度框架(续)](https://www.cnblogs.com/rongdi/p/11940402.html)
[笑话：大厂都在用的任务调度框架我能不知道吗？？？](https://www.cnblogs.com/yinjihuan/p/12849787.html)
[分布式定时任务调度框架实践](https://www.cnblogs.com/vivotech/p/12395381.html)
### 分布式技术架构演化
[分析分布式技术架构演化的常用套路](https://www.cnblogs.com/zhuhuix/p/13625022.html)
```markdown
1、单机架构
2、应用服务与数据服务分离
3、应用服务器集群架构
    3.1 应用服务器集群架构下的Session管理
4、数据库读写分离
5、利用缓存技术进行加速
6、分布式数据库系统与分布式文件系统
7、NoSQL数据库作为补充
8、使用搜索引擎
9. 分布式服务
```
### 分布式锁
[springboot利用consul实现分布式锁](https://www.cnblogs.com/wenwuxianren/p/11181786.html)
```markdown

``` 
### 高并发系统的设计与实现
```markdown
在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流。
    缓存：缓存比较好理解，在大型高并发系统中，如果没有缓存数据库将分分钟被爆，系统也会瞬间瘫痪。使用缓存不单单能够提升系统访问速度、提高并发访问量，
        也是保护数据库、保护系统的有效方式。大型网站一般主要是“读”，缓存的使用很容易被想到。在大型“写”系统中，缓存也常常扮演者非常重要的角色。
        比如累积一些数据批量写入，内存里面的缓存队列（生产消费），以及HBase写数据的机制等等也都是通过缓存提升系统的吞吐量或者实现系统的保护措施。
        甚至消息中间件，你也可以认为是一种分布式的数据缓存。
    降级：服务降级是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。
        降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。根据服务方式：可以拒接服务，可以延迟服务，也有时候可以随机服务。
        根据服务范围：可以砍掉某个功能，也可以砍掉某些模块。总之服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有好。
    限流：限流可以认为服务降级的一种，限流就是限制系统的输入和输出流量已达到保护系统的目的。一般来说系统的吞吐量是可以被测算的，为了保证系统的稳定运行，
        一旦达到的需要限制的阈值，就需要限制流量并采取一些措施以完成限制流量的目的。比如：延迟处理，拒绝处理，或者部分拒绝处理等等。
``` 
### 一致性hash算法
[动手实现一致性哈希算法,并搭建环境测试其负载均衡](https://www.cnblogs.com/tanshaoshenghao/p/10816480.html)
[面试官常问的“一致性哈希”，都在这 18 张图里](https://www.cnblogs.com/siyuanwai/p/14009796.html)
```markdown
一致性哈希算法通过把每台服务器的哈希值打在哈希环上, 把哈希环分成不同的段, 然后对到来的请求计算哈希值从而得知该请求所归属的服务器。
    目的：这个办法解决了传统服务器增减机器时需要重新计算哈希的麻烦。
    如果服务器的数量较少,可能导致计算出的哈希值相差较小,在哈希环上分布不均匀,导致某台服务器过载。
    为了解决负载均衡问题,我们引入虚拟节点技术, 为每台服务器分配一定数量的节点, 通过节点的哈希值在哈希环上进行划分。
    这样一来，我们就可以根据机器的性能为其分配节点，性能好就多分配一点，差就少一点，从而达到负载均衡。
```
### 接口幂等性
[高并发下接口幂等性解决方案](https://www.cnblogs.com/linjiqin/p/9678022.html)
```markdown
在编程中.一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。
幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。
二、幂等性场景
1、查询操作：查询一次和查询多次，在数据不变的情况下，查询结果是一样的。select是天然的幂等操作；
2、删除操作：删除操作也是幂等的，删除一次和多次删除都是把数据删除。(注意可能返回结果不一样，删除的数据不存在，返回0，删除的数据多条，返回结果多个) ；
3、唯一索引：防止新增脏数据。比如：支付宝的资金账户，支付宝也有用户账户，每个用户只能有一个资金账户，怎么防止给用户创建资金账户多个，那么给资金账户表中的用户ID加唯一索引，所以一个用户新增成功一个资金账户记录。要点：唯一索引或唯一组合索引来防止新增数据存在脏数据（当表存在唯一索引，并发时新增报错时，再查询一次就可以了，数据应该已经存在了，返回结果即可）；
4、token机制：防止页面重复提交。
    原理上通过session token来实现的(也可以通过redis来实现)。当客户端请求页面时，服务器会生成一个随机数Token，并且将Token放置到session当中，然后将Token发给客户端（一般通过构造hidden表单）。
    下次客户端提交请求时，Token会随着表单一起提交到服务器端。
    服务器端第一次验证相同过后，会将session中的Token值更新下，若用户重复提交，第二次的验证判断将失败，因为用户提交的表单中的Token没变，但服务器端session中Token已经改变了。
5、悲观锁
获取数据的时候加锁获取。select * from table_xxx where id='xxx' for update; 注意：id字段一定是主键或者唯一索引，不然是锁表，会死人的；悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用；
6、乐观锁——乐观锁只是在更新数据那一刻锁表，其他时间不锁表，所以相对于悲观锁，效率更高。乐观锁的实现方式多种多样可以通过version或者其他状态条件：
    1. 通过版本号实现update table_xxx set name=#name#,version=version+1 where version=#version#如下图(来自网上)；
    2. 通过条件限制 update table_xxx set avai_amount=avai_amount-#subAmount# where avai_amount-#subAmount# >= 0要求：quality-#subQuality# >= ，这个情景适合不用版本号，只更新是做数据安全校验，适合库存模型，扣份额和回滚份额，性能更高；
7、分布式锁
    如果是分布是系统，构建全局唯一索引比较困难，例如唯一性的字段没法确定，这时候可以引入分布式锁，通过第三方的系统(redis或zookeeper)，在业务系统插入数据或者更新数据，获取分布式锁，然后做操作，之后释放锁，这样其实是把多线程并发的锁的思路，引入多多个系统，也就是分布式系统中得解决思路。要点：某个长流程处理过程要求不能并发执行，可以在流程执行之前根据某个标志(用户ID+后缀等)获取分布式锁，其他流程执行时获取锁就会失败，也就是同一时间该流程只能有一个能执行成功，执行完成后，释放分布式锁(分布式锁要第三方系统提供)；
8、select + insert
    并发不高的后台系统，或者一些任务JOB，为了支持幂等，支持重复执行，简单的处理方法是，先查询下一些关键数据，判断是否已经执行过，在进行业务处理，就可以了。注意：核心高并发流程不要用这种方法；
9、状态机幂等
    在设计单据相关的业务，或者是任务相关的业务，肯定会涉及到状态机(状态变更图)，就是业务单据上面有个状态，状态在不同的情况下会发生变更，一般情况下存在有限状态机，这时候，如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的，这样的话，保证了有限状态机的幂等。注意：订单等单据类业务，存在很长的状态流转，一定要深刻理解状态机，对业务系统设计能力提高有很大帮助
10、对外提供接口的api如何保证幂等
    如银联提供的付款接口：需要接入商户提交付款请求时附带：source来源，seq序列号；source+seq在数据库里面做唯一索引，防止多次付款(并发时，只能处理一个请求) 。
重点：对外提供接口为了支持幂等调用，接口有两个字段必须传，一个是来源source，一个是来源方序列号seq，这个两个字段在提供方系统里面做联合唯一索引，这样当第三方调用时，先在本方系统里面查询一下，是否已经处理过，返回相应处理结果；没有处理过，进行相应处理，返回结果。注意，为了幂等友好，一定要先查询一下，是否处理过该笔业务，不查询直接插入业务系统，会报错，但实际已经处理了。
```
## 优先博客文章解析
### [1.从单体到分布式，必须解决的四个问题](https://www.cnblogs.com/mcgrady/p/12837680.html)
```markdown
一，session共享解决方案
    第1种是配置nginx的负载集群策略为ip_hash，
    第2种是将session存储到其它地方，一般推荐放到redis中
二，本地缓存(当从单体迁移到集群后，就会面临缓存同步的问题)解决方案
    最佳实践是上分布式缓存，既解决了缓存同步的问题，也释放了应用服务器的内存资源
三，文件服务
    应用服务器在上集群之前，文件通常会放在本地，或者单独的文件服务器上，因为文件服务需要占用大量的硬盘空间，以上两种方案都无法很好的解决硬盘扩容的问题
    最佳实践是放到云存储上，比如阿里云的OSS，或者腾讯云的COS上，这样可以做到按需扩容
四，分布式环境下线程同步问题    
    分布式锁：这里推荐使用redis的setnx
```
### [2.我司使用了六年的分布式锁](https://www.cnblogs.com/chopper-poet/p/10802242.html)
```markdown
在单体应用时代，我们使用jvm提供的锁就可以很好的工作，
到了分布式应用时代，jvm提供的锁就行不通，要借助一些跨jvm的临界资源来支持锁的相关语义，比如redis，zookeeper等。
加锁过程分析
释放锁过程分析
```
### [3.万字长文！不为人所知的分布式锁实现全都在这里了](https://www.cnblogs.com/ldws/p/12155003.html)

### ​[分布式UUID生成方案](https://www.cnblogs.com/jajian/p/11101213.html)
[实用向—总结一些唯一ID生成方式](https://www.cnblogs.com/dafanjoy/p/13690888.html)
[分布式配置中心选型](https://www.cnblogs.com/xiaodf/p/11214775.html)
​[分布式主动感知在智能运维中的实践](https://www.cnblogs.com/yixinjishu/p/11156257.html)](https://www.cnblogs.com/yixinjishu/p/11156257.html)
[编写你的第一个 Java 版 Raft 分布式 KV 存储](https://www.cnblogs.com/stateis0/p/10259339.html)
[防止数据重复提交的6种方法(超简单)！](https://www.cnblogs.com/vipstone/p/13328386.html)
### 高并发
[高并发，你真的了解吗？](https://www.cnblogs.com/huaweiyun/p/13517499.html)
>> 本文介绍高并发系统的度量指标，讲述高并发系统的设计思路，再梳理高并发的关键技术，最后结合作者的经验做一些延伸探讨。
```markdown
软件系统有三个追求：高性能、高并发、高可用，俗称三高。
高并发（High Concurrency）。并发是操作系统领域的一个概念，指的是一段时间内多任务流交替执行的现象，
    后来这个概念被泛化，高并发用来指大流量、高请求的业务情景，比如春运抢票，电商双十一，秒杀大促等场景。
1、高并发的度量指标
    并发的指标一般有QPS、TPS、IOPS都是可归为系统吞吐率。
    QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，
    我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。
    通常，数据库单机每秒也就能抗住几千这个量级，而做逻辑处理的服务单台每秒抗几万、甚至几十万都有可能，
    而消息队列等中间件单机每秒处理个几万没问题，所以我们经常听到每秒处理数百万、数千万的消息中间件集群，而像阿某的API网关，每日百亿请求也有可能。
2、高并发的设计思路
    高并发的设计思路有两个方向：
        1.垂直方向扩展，也叫竖向扩展。垂直方向：提升单机能力
            提升单机处理能力又可分为硬件和软件两个方面：
            1.硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽
            2.软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24X7。
        2.水平方向扩展，也叫横向扩展。水平方向：分布式集群
            为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。高并发系统的实施也主要围绕水平方向展开。
3、高并发的关键技术
    1.集群化：负载均衡
        负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：
        1.DNS负载均衡，客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，
            同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，
            因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。
        2.硬件负载均衡，通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。
        3.软件负载均衡，根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，
            阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。
        所以，完整的负载均衡链路是 client <-> DNS负载均衡 -> F5 -> LVS/SLB -> NGINX
        不管选择哪种LB策略，或者组合LB策略，逻辑上，我们都可以视为负载均衡层，通过添加负载均衡层，我们将负载均匀分散到了后面的服务集群，
            具备基础的高并发能力，但这只是万里长征第一步。
    2.数据库层面：分库分表+读写分离
        把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。
            从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。
        如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，
            而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。
    3.读多写少：缓存
        一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。
        在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，
            通过缓存集群，就可以用更少的机器资源承载更高的并发。
        缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。
        CDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。
        缓存也有很多需要谨慎处理的问题：
        1.一致性问题：(a)更新db成功+更新cache失败->不一致 (b)更新db失败+更新cache成功->不一致 ©更新db成功+淘汰缓存失败->不一致
        2.缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。
        解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失
        3.缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，
        降低同一时间点失效淘汰缓存数，避免集体失效事件发生
    4.高写入：消息中间件
        比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。
        消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。业界有很多著名的消息中间件，比如ZeroMQ，rabbitMQ，kafka等。
        消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，
        比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。
    5.避免挤兑：流控（限流）
        流控的关键是流控算法，有4种常见的流控算法。
        1.计数器算法（固定窗口）：计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。
            计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。
        2.滑动窗口算法：将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，
            那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。
        3.漏桶算法：访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。
            漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。
        4.令牌桶算法：程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，
            如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。
4、高并发的实践经验
    接入-逻辑-存储是经典的互联网后端分层，但随着业务规模的提高，逻辑层的复杂度也上升了，
    所以，针对逻辑层的架构设计也出现很多新的技术和思路，常见的做法包括系统拆分，微服务。
    除此之外，也有很多业界的优秀实践，包括某信服务器通过协程（无侵入，已开源libco）改造，极大的提高了系统的并发度和稳定性，
        另外，缓存预热，预计算，批量读写（减少IO），池技术等也广泛应用在实践中，有效的提升了系统并发能力。
    为了提升并发能力，逻辑后端对请求的处理，一般会用到生产者-消费者多线程模型，即I/O线程负责网络IO，协议编解码，网络字节流被解码后产生的协议对象，
        会被包装成task投入到task queue，然后worker线程会从该队列取出task执行，有些系统会用多进程而非多线程，通过共享存储，维护2个方向的shm queue，
        一个input q，一个output q，为了提高并发度，有时候会引入协程，协程是用户线程态的多执行流，它的切换成本更低，通常有更好的调度效率。
    另外，构建漏斗型业务或者系统，从客户端请求到接入层，到逻辑层，到DB层，层层递减，过滤掉请求，Fail Fast（尽早发现尽早过滤），嘴大屁眼小，哈哈。
    漏斗型系统不仅仅是一个技术模型，它也可以是一个产品思维，配合产品的用户分流，逻辑分离，可以构建全方位的立体模型。
```

###

