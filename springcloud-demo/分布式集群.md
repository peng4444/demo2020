# 分布式集群

[TOC]

## 理论基础
[架构师都该懂的CAP定理](https://www.cnblogs.com/one12138/p/13341366.html)
[关于ACID，BASE和CAP定理的探究](https://www.cnblogs.com/misterchaos/p/13549341.html)
```markdown
ACID是传统关系型数据库事务的四个特性：
    原子性(Atomicity): 指所有在事务中的操作要么都成功，要么都不成功，所有的操作都不可分割，没有中间状态。一旦某一步执行失败，就会全部回滚到初始状态。
    一致性(Consistency): 在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这表示写入的资料必须完全符合所有的预设约束、触发器、级联回滚等
    隔离性(Isolation)：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
    事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。
    持久性(Durability)：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失
    具有ACID特性的数据库系统，可以保证在写入或更新数据时，事务是正确可靠的。ACID的目标是保证数据的正确性和一致性。
BASE的思想是，为了提高系统的可用性，允许在某些时候，某个节点返回的不是最新的数据，但是在一段时间之后，系统中的数据最终会达到一致。
    这种做法可以在系统访问高峰时牺牲一定的一致性，保证可用性，在高峰过后又恢复数据的一致性。
    基本可用（Basically Available）：分布式系统在出现不可预知故障的时候，允许损失部分可用性
    软状态（Soft State）：允许系统中的数据存在中间状态，即不同节点上的数据不一致
    最终一致性（Eventually Consistent）：软状态不能一直持续，在一定期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性
CAP定理:在一个跨区域网络连接，共享数据的分布式系统中，一致性（Consistency），可用性（Availability）和分区容错性（Partition Tolerance）
    由于分布式系统必须保证分区容错性，所以只能选择AP原则或者CP原,这三个约束属性最终只能同时满足二个。
    一致性（Consistency）：客户端进行读操作得到的数据永远是最近一次写入的数据，要求了对数据读写的强一致性。
    可用性（Availability）：客户端的请求在限定时间内总能从非故障的系统节点得到正常的响应，其中不能有超时，不能出错如502之类。
    分区容错性（Partition tolerance）：就是出现网络分区现象，即节点间无法正常通信，数据同步出现延时等情况时，系统仍能继续提供服务。
对比Eureka和Zookeeper在CAP中的选择
    CP原则：如分布式数据库、分布式锁，服务注册中心Zookeeper,Consul,Mongodb
    AP原则：如DNS，服务注册中心Eureka
    Nacos：AP和CP两种模式都可以满足
```
## 分布式事务解决方案
[3天深入学习分布式事务应用及解决方案]( https://www.bilibili.com/video/BV1GJ411m73n )

[微服务架构的分布式事务控制解决方案]( https://www.bilibili.com/video/BV1Q4411y7ip )

[如何选择分布式事务解决方案？](http://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247496338&idx=1&sn=088c5980f84feb7133f83a0835d49bc9&chksm=e92acf9dde5d468bc9d88eefdd7ea89d58353541d85f79d5cd9b09c67fe06a8a61ca13320968&mpshare=1&scene=23&srcid=&sharer_sharetime=1590626960950&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)

[参考视频1：分布式事务解决方案](https://www.bilibili.com/video/av64323822)

[参考视频2：阿里分布式事务框架Seata原理解析](https://www.bilibili.com/video/av50531999)

[参考视频3：阿里如何解决分布式事务](https://www.bilibili.com/video/av40630844)

[分布式事务](https://www.cnblogs.com/xiaobingblog/p/11540341.html)

[SpringBoot的事物Transaction使用的教程](https://www.cnblogs.com/xuwujing/p/11184162.html)

[终于跑通分布式事务框架tcc-transaction的示例项目](https://www.cnblogs.com/bigdataZJ/p/tcc-transaction-sample.html)

[TCC 分布式事务](https://www.cnblogs.com/jajian/p/10014145.html)

[浅谈分布式事务与TX-LCN](https://www.cnblogs.com/tanshaoshenghao/p/11684727.html)

[分布式事务解决方案：TCC与最终一致](https://www.cnblogs.com/sw008/p/11054277.html)

[阿里分布式事务seata入门（采坑）](https://www.cnblogs.com/sky-chen/p/11419942.html)

[Spring Cloud Alibaba | 微服务分布式事务之Seata](https://www.cnblogs.com/babycomeon/p/11504210.html)

[Spring Cloud同步场景分布式事务怎样做？试试Seata](https://www.cnblogs.com/zlt2000/p/11525417.html)

[[扛住阿里双十一高并发流量，Sentinel是怎么做到的？](https://www.cnblogs.com/caison/p/11673047.html)]

[我是如何基于二阶段递交及悲观锁实现分布式事务的](https://www.cnblogs.com/BaiCai/p/11184009.html)

```markdown
原理：两阶段提交
分布式事务解决方案：
	1.消息队列(RocketMQ)
	2.AT -- 业务无侵入   远程调用提交前wait    TxManager
	3.TCC -- 业务有侵入  try -- commit -- cacel
	4.
```

## Dubbo原理与源码分析
[参考视频1：深刻了解dubbo底层源码](https://www.bilibili.com/video/av58338686)

[参考视频2：Dubbo底层原理与面试经验](https://www.bilibili.com/video/av53428315/)

[从零开始认识Dubbo](https://www.cnblogs.com/alterem/p/11211728.html)

[dubbo](https://www.cnblogs.com/xxbiao/tag/dubbo/)

[手写RPC框架注释代码](https://www.cnblogs.com/mseddl/p/11531465.html)

[一文带你实现RPC框架](https://www.cnblogs.com/endless-code/p/11235624.html)

[微服务调用为啥用RPC框架，http不更简单吗？](https://zhuanlan.zhihu.com/p/61364466)

[Dubbo服务注册与发现](https://www.cnblogs.com/mzq123/p/11221570.html)

[springboot2.x纯注解整合dubbo](https://www.cnblogs.com/chywx/p/11180719.html)

[Dubbo 与 Spring Cloud 完美结合](https://www.cnblogs.com/babycomeon/p/11546737.html)

[[Dubbo面试八连问，这些你都能答上来吗？](https://www.cnblogs.com/javazhiyin/p/11966271.html)]

[[Zookeeper+Dubbo项目demo搭建](https://www.cnblogs.com/iUtopia/p/11653098.html)]

[Dubbo 入门-细说分布式与集群](https://www.cnblogs.com/yangyuanhu/p/12439106.html)

[吐血输出：2万字长文带你细细盘点Dubbo五种负载均衡策略。](https://www.cnblogs.com/thisiswhy/p/13020501.html)
## Zookeeper技术
[如何用 Zookeeper 实现分布式锁？（附源码）](https://mp.weixin.qq.com/s?__biz=MzUxOTc4NjEyMw==&mid=2247484568&idx=1&sn=d2ae43f697a01d4f4a0a05c3b0e48649&chksm=f9f51f7cce82966a55e8bb51d54f78094112252cba489e77c7aa272c98c24ecbb4b004737af9&mpshare=1&scene=23&srcid=#rd)

[基于缓存或zookeeper的分布式锁实现](https://www.cnblogs.com/jmcui/p/11186224.html)

[zookeeper实现分布式锁总结，看这一篇足矣（设计模式应用实战）](https://www.cnblogs.com/sx-bj-srr/p/zookeeper.html)

[zookeeper源码](https://www.cnblogs.com/sunshine-2015/category/1450046.html)

[[万字长文带你入门Zookeeper！！！](https://www.cnblogs.com/Chenjiabing/p/12678607.html)]

## Kafka技术
[全网最通俗易懂的Kafka入门！](https://www.cnblogs.com/Java3y/p/11982381.html)

[图解kafka解析设计原理](https://www.cnblogs.com/lbzhello/p/kafka-20190708.html) 

[[再过半小时，你就能明白kafka的工作原理了](https://www.cnblogs.com/sujing/p/10960832.html)]

[[基于Kafka的实时计算引擎如何选择？Flink or Spark？](https://www.cnblogs.com/smartloli/p/10963221.html)]

[[源码分析 Kafka 消息发送流程(文末附流程图)](https://www.cnblogs.com/dingwpmz/p/12153036.html)]

```markdown
[Kafka常用命令](https://blog.csdn.net/qq_33689414/article/details/81046502)
```

## Flink技术
【Flink】[实时计算引擎FLink](https://www.cnblogs.com/zhisheng/p/11332529.html)

[[flink入门实战总结](https://www.cnblogs.com/davidwang456/p/11256748.html)]

[[如何进行Flink项目构建,快速开发Flink应用程序?](https://www.cnblogs.com/bigdata1024/p/11938727.html)]

[[Flink 灵魂两百问，这谁顶得住？](https://www.cnblogs.com/zhisheng/p/11254773.html)]

[[Flink基本的API](https://www.cnblogs.com/duma/p/10964985.html)]

[Flink中的CEP复杂事件处理 (源码分析)](https://www.cnblogs.com/ljygz/p/11978386.html)

[阿龙学堂-Flink简介](https://blog.csdn.net/superzyl/article/details/79748092)

[Blink 有何特别之处？菜鸟供应链场景最佳实践](https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&mid=2247490270&idx=1&sn=ef24430ebe4dfa053c77a403e6ebe37d&chksm=e92927d1de5eaec7b281769988025f5db93bf067bf21fe32bba6a790d9e5629a3e5c592df5a3&mpshare=1&scene=23&srcid=#rd)
[《从0到1学习Flink》—— Flink 项目如何运行？](https://www.cnblogs.com/zhisheng/p/10326796.html#commentform)
```markdown

```

## K8S技术
[K8S安装](参考书k8s权威指南)

[高可用的K8S集群部署方案](https://www.cnblogs.com/ants/p/11489598.html)

[[简单了解一下K8S，并搭建自己的集群](https://www.cnblogs.com/detectiveHLH/p/12048795.html)]

[[6 个 K8s 日志系统建设中的典型问题，你遇到过几个？](https://www.cnblogs.com/alisystemsoftware/p/11544392.html)]

[[spring-cloud-kubernetes官方demo运行实战](https://www.cnblogs.com/bolingcavalry/p/11445732.html)]

[[从零开始入门 K8s| 详解 Pod 及容器设计模式](https://www.cnblogs.com/alisystemsoftware/p/11551525.html)]

[[入门级实操教程！从概念到部署，全方位了解K8S Ingress！](https://www.cnblogs.com/rancherlabs/p/12034075.html)]

[[超长干货丨Kubernetes网络快速入门完全指南](https://www.cnblogs.com/rancherlabs/p/12101762.html)]

```markdown
Kubernetes 是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。使用 Kubernetes 我们可以：
快速部署应用
快速扩展应用
无缝对接新的应用功能
节省资源，优化硬件资源的使用
Kubernetes 的目标是促进完善组件和工具的生态系统，以减轻应用程序在公有云或私有云中运行的负担。
```
[Kubernetes+Docker+Istio 容器云实践](https://www.cnblogs.com/yixinjishu/p/11691932.html)
[[k8s 开船记-首航：博客站点从 docker swarm 切换到 k8s](https://www.cnblogs.com/cmt/p/12033446.html)]

![K8S架构](https://www.funtl.com/assets1/Lusifer_20190531065907.png)

## 集群
[参考资料：cyc2018大佬]
### 1. 负载均衡
```markdown
集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。
负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。
负载均衡器可以用来实现高可用以及伸缩性：
    高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
    伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。
负载均衡器运行过程包含两个部分：
    1. 根据负载均衡算法得到转发的节点；
    2. 进行转发。
```
#### 1.1 负载均衡算法
```markdown
1. 轮询（Round Robin）:轮询算法把每个请求轮流发送到每个服务器上。
    比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载
2. 加权轮询（Weighted Round Robbin）：加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。
3. 最少连接（least Connections）：最少连接算法就是将请求发送给当前最少连接数的服务器上。
    由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。
4. 加权最少连接（Weighted Least Connection）：在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。
5. 随机算法（Random）：把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。
6. 源地址哈希法 (IP Hash)：源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。
    可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）
```
#### 1.2 转发实现
```markdown
1. HTTP 重定向
HTTP重定向负载均衡服务器使用某种负载均衡算法计算得到服务器的IP 址之后，将该地址写入HTTP重定向报文中，状态码为302。
客户端收到重定向报文之后，需要重新向服务器发起请求。
缺点：
    需要两次请求，因此访问延迟比较高；
    HTTP 负载均衡器处理能力有限，会限制集群的规模。
该负载均衡转发的缺点比较明显，实际场景中很少使用它。
2. DNS 域名解析
在 DNS 解析域名的同时使用负载均衡算法计算服务器 IP 地址。
优点：
    DNS 能够根据地理位置进行域名解析，返回离用户最近的服务器 IP 地址。
缺点：
    由于 DNS 具有多级结构，每一级的域名记录都可能被缓存，当下线一台服务器需要修改 DNS 记录时，需要过很长一段时间才能生效。
大型网站基本使用了DNS做为第一级负载均衡手段，然后在内部使用其它方式做第二级负载均衡。也就是说，域名解析的结果为内部的负载均衡服务器IP地址。
3. 反向代理服务器
反向代理服务器位于源服务器前面，用户的请求需要先经过反向代理服务器才能到达源服务器。反向代理可以用来进行缓存、日志记录等，同时也可以用来做为负载均衡服务器。
在这种负载均衡转发方式下，客户端不直接请求源服务器，因此源服务器不需要外部IP地址，而反向代理需要配置内部和外部两套IP地址。
优点：
    与其它功能集成在一起，部署简单。
缺点：
    所有请求和响应都需要经过反向代理服务器，它可能会成为性能瓶颈。
4. 网络层
在操作系统内核进程获取网络数据包，根据负载均衡算法计算源服务器的IP地址，并修改请求数据包的目的IP地址，最后进行转发。
源服务器返回的响应也需要经过负载均衡服务器，通常是让负载均衡服务器同时作为集群的网关服务器来实现。
优点：
    在内核进程中进行处理，性能比较高。
缺点：
    和反向代理一样，所有的请求和响应都经过负载均衡服务器，会成为性能瓶颈。
5. 链路层
在链路层根据负载均衡算法计算源服务器的MAC地址，并修改请求数据包的目的MAC地址，并进行转发。通过配置源服务器的虚拟IP地址和负载均衡服务器的IP地址一致，
从而不需要修改IP地址就可以进行转发。也正因为IP地址一样，所以源服务器的响应不需要转发回负载均衡服务器，可以直接转发给客户端，避免了负载均衡服务器的成为瓶颈。
这是一种三角传输模式，被称为直接路由。对于提供下载和视频服务的网站来说，直接路由避免了大量的网络传输数据经过负载均衡服务器。
这是目前大型网站使用最广负载均衡转发方式，在 Linux 平台可以使用的负载均衡服务器为 LVS（Linux VirtualServer）。
```
### 2. 集群下的Session管理
```markdown
一个用户的Session信息如果存储在一个服务器上，那么当负载均衡器把用户的下一个请求转发到另一个服务器，
由于服务器没有用户的Session信息，那么该用户就需要重新进行登录等操作。
Sticky Session:需要配置负载均衡器，使得一个用户的所有请求都路由到同一个服务器，这样就可以把用户的Session存放在该服务器中。
               缺点：
               当服务器宕机时，将丢失该服务器上的所有 Session。
Session Replication:在服务器之间进行Session同步操作，每个服务器都有所有用户的Session信息，因此用户可以向任何一个服务器进行请求。
                缺点：
                占用过多内存；
                同步过程占用网络带宽以及服务器处理器时间。
Session Server:使用一个单独的服务器存储Session数据，可以使用传统的MySQL，也使用Redis 或者Memcached这种内存型数据库。
                优点：
                为了使得大型网站具有伸缩性，集群中的应用服务器通常需要保持无状态，那么应用服务器不能存储用户的会
                话信息。Session Server 将用户的会话信息单独进行存储，从而保证了应用服务器的无状态。
                缺点：
                需要去实现存取 Session 的代码。
```

## 分布式
【分布式系统】[分布式系统](https://www.cnblogs.com/Zachary-Fan/p/distributedsystems.html)
[随笔分类 - 【分布式】-- 分库分表](https://www.cnblogs.com/qdhxhz/category/1558200.html)
## 优先博客文章解析
### [1.从单体到分布式，必须解决的四个问题](https://www.cnblogs.com/mcgrady/p/12837680.html)
```markdown
一，session共享解决方案
    第1种是配置nginx的负载集群策略为ip_hash，
    第2种是将session存储到其它地方，一般推荐放到redis中
二，本地缓存(当从单体迁移到集群后，就会面临缓存同步的问题)解决方案
    最佳实践是上分布式缓存，既解决了缓存同步的问题，也释放了应用服务器的内存资源
三，文件服务
    应用服务器在上集群之前，文件通常会放在本地，或者单独的文件服务器上，因为文件服务需要占用大量的硬盘空间，以上两种方案都无法很好的解决硬盘扩容的问题
    最佳实践是放到云存储上，比如阿里云的OSS，或者腾讯云的COS上，这样可以做到按需扩容
四，分布式环境下线程同步问题    
    分布式锁：这里推荐使用redis的setnx
```
### [2.我司使用了六年的分布式锁](https://www.cnblogs.com/chopper-poet/p/10802242.html)
```markdown
在单体应用时代，我们使用jvm提供的锁就可以很好的工作，
到了分布式应用时代，jvm提供的锁就行不通，要借助一些跨jvm的临界资源来支持锁的相关语义，比如redis，zookeeper等。
加锁过程分析
释放锁过程分析
```
### [3.万字长文！不为人所知的分布式锁实现全都在这里了](https://www.cnblogs.com/ldws/p/12155003.html)
```markdown

```
### [4.分布式系统中session一致性问题](https://www.cnblogs.com/jajian/p/10962989.html)
#### 问题存在
```markdown
在单机系统中，用户登陆之后，服务端会保存用户的会话信息，只要用户不退出重新登陆，在一段时间内用户可以一直访问该网站，无需重复登陆。
用户的信息存在服务端的session中，session中可以存放服务端需要的一些用户信息，例如用户ID，所属公司companyId，所属部门deptId等等。
当下流行的微服务。虽然在用户端看来系统仍然是一个整体，但在技术端来说业务则被拆分成多个模块，各个模块之间相互独立，甚至不在同一台物理机器上，模块之间通过RPC进行通信。
```
#### 问题解决:从以下几个方面想到解决的方法
```markdown
每个服务端存储一份，通过同步的方式保证一致性，但是这种方式有个很明显的缺点：session的同步需要数据传输，占内网带宽，有时延，
网络不稳定的时候会造成部分系统同步延迟，那么就不能保证 ession一致性。而且所有服务端都包含所有session数据，数据量受内存限制，无法水平扩展。
1.在用户首次登陆的时候将用户信息放到 Token并缓存到 Redis 中，同时设置一个过期时间。
2.可以定义一个拦截器 SessionInterceptor，当访问web接口的时候检验用户的token信息，判断用户是否登陆，
    未登录的情况下一些业务接口是无法访问的，以及在登陆的情况下拿到我们需要的用户信息，如userId。
以上实现方式简单易用，而且Redis 在分布式系统中的使用率也很高，所以无需额外的技术引入。
可以支持水平扩展，数据库或缓存水平切分即可，服务端重启或者扩容都不会有session丢失的情况发生。
```
### ​[分布式UUID生成方案](https://www.cnblogs.com/jajian/p/11101213.html)

##
[分布式配置中心选型](https://www.cnblogs.com/xiaodf/p/11214775.html)
​[分布式主动感知在智能运维中的实践](https://www.cnblogs.com/yixinjishu/p/11156257.html)](https://www.cnblogs.com/yixinjishu/p/11156257.html)

[编写你的第一个 Java 版 Raft 分布式 KV 存储](https://www.cnblogs.com/stateis0/p/10259339.html)

## 高并发
[高并发，你真的了解吗？](https://www.cnblogs.com/huaweiyun/p/13517499.html)
>> 本文介绍高并发系统的度量指标，讲述高并发系统的设计思路，再梳理高并发的关键技术，最后结合作者的经验做一些延伸探讨。
```markdown
软件系统有三个追求：高性能、高并发、高可用，俗称三高。
高并发（High Concurrency）。并发是操作系统领域的一个概念，指的是一段时间内多任务流交替执行的现象，
    后来这个概念被泛化，高并发用来指大流量、高请求的业务情景，比如春运抢票，电商双十一，秒杀大促等场景。
1、高并发的度量指标
    并发的指标一般有QPS、TPS、IOPS都是可归为系统吞吐率。
    QPS越高系统能hold住的请求数越多，但光关注这几个指标不够，
    我们还需要关注RT，即响应时间，也就是从发出request到收到response的时延，这个指标跟吞吐往往是此消彼长的，我们追求的是一定时延下的高吞吐。
    通常，数据库单机每秒也就能抗住几千这个量级，而做逻辑处理的服务单台每秒抗几万、甚至几十万都有可能，
    而消息队列等中间件单机每秒处理个几万没问题，所以我们经常听到每秒处理数百万、数千万的消息中间件集群，而像阿某的API网关，每日百亿请求也有可能。
2、高并发的设计思路
    高并发的设计思路有两个方向：
        1.垂直方向扩展，也叫竖向扩展。垂直方向：提升单机能力
            提升单机处理能力又可分为硬件和软件两个方面：
            1.硬件方向，很好理解，花钱升级机器，更多核更高主频更大存储空间更多带宽
            2.软件方向，包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，但这玩意儿天花板低，就像提升个人产出一样，996、007、最多24X7。
        2.水平方向扩展，也叫横向扩展。水平方向：分布式集群
            为了解决分布式系统的复杂性问题，一般会用到架构分层和服务拆分，通过分层做隔离，通过微服务解耦。高并发系统的实施也主要围绕水平方向展开。
3、高并发的关键技术
    1.集群化：负载均衡
        负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，它分3种：
        1.DNS负载均衡，客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，DNS会按一定的策略（比如就近策略）把URL转换成IP地址，
            同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，它是一种粗粒度的负载均衡，它只用URL前半部分，
            因为DNS负载均衡一般采用就近原则，所以通常能降低时延，但DNS有cache，所以也会更新不及时的问题。
        2.硬件负载均衡，通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。
        3.软件负载均衡，根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），软件负载均衡配置灵活，扩展性强，
            阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。
        所以，完整的负载均衡链路是 client <-> DNS负载均衡 -> F5 -> LVS/SLB -> NGINX
        不管选择哪种LB策略，或者组合LB策略，逻辑上，我们都可以视为负载均衡层，通过添加负载均衡层，我们将负载均匀分散到了后面的服务集群，
            具备基础的高并发能力，但这只是万里长征第一步。
    2.数据库层面：分库分表+读写分离
        把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。
            从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。
        如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，
            而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。
    3.读多写少：缓存
        一般系统的写入请求远少于读请求，针对写少读多的场景，很适合引入缓存集群。
        在写数据库的时候同时写一份数据到缓存集群里，然后用缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，所以，这样的话，
            通过缓存集群，就可以用更少的机器资源承载更高的并发。
        缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。
        CDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。
        缓存也有很多需要谨慎处理的问题：
        1.一致性问题：(a)更新db成功+更新cache失败->不一致 (b)更新db失败+更新cache成功->不一致 ©更新db成功+淘汰缓存失败->不一致
        2.缓存穿透：查询一定不存在的数据，会穿透缓存直接压到数据库，从而导致缓存失去作用，如果有人利用这个漏洞，大量查询一定不存在的数据，会对数据库造成压力，甚至打挂数据库。
        解决方案：布隆过滤器 或者 简单的方案，查询不存在的key，也把空结果写入缓存（设置较短的过期淘汰时间），从而降低命失
        3.缓存雪崩：如果大量缓存在一个时刻同时失效，则请求会转到DB，则对DB形成压迫，导致雪崩。简单的解决方案是为缓存失效时间添加随机值，
        降低同一时间点失效淘汰缓存数，避免集体失效事件发生
    4.高写入：消息中间件
        比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。
        消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。业界有很多著名的消息中间件，比如ZeroMQ，rabbitMQ，kafka等。
        消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，
        比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。
    5.避免挤兑：流控（限流）
        流控的关键是流控算法，有4种常见的流控算法。
        1.计数器算法（固定窗口）：计数器算法是使用计数器在周期内累加访问次数，当达到设定的限流值时，触发限流策略，下一个周期开始时，进行清零，重新计数，实现简单。
            计数器算法方式限流对于周期比较长的限流，存在很大的弊端，有严重的临界问题。
        2.滑动窗口算法：将时间周期分为N个小周期，分别记录每个小周期内访问次数，并且根据时间滑动删除过期的小周期，当滑动窗口的格子划分的越多，
            那么滑动窗口的滚动就越平滑，限流的统计就会越精确。此算法可以很好的解决固定窗口算法的临界问题。
        3.漏桶算法：访问请求到达时直接放入漏桶，如当前容量已达到上限（限流值），则进行丢弃（触发限流策略）。
            漏桶以固定的速率进行释放访问请求（即请求通过），直到漏桶为空。分布式环境下实施难度高。
        4.令牌桶算法：程序以r（r=时间周期/限流值）的速度向令牌桶中增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，
            如获取到令牌则通过请求，否则触发限流策略。分布式环境下实施难度高。
4、高并发的实践经验
    接入-逻辑-存储是经典的互联网后端分层，但随着业务规模的提高，逻辑层的复杂度也上升了，
    所以，针对逻辑层的架构设计也出现很多新的技术和思路，常见的做法包括系统拆分，微服务。
    除此之外，也有很多业界的优秀实践，包括某信服务器通过协程（无侵入，已开源libco）改造，极大的提高了系统的并发度和稳定性，
        另外，缓存预热，预计算，批量读写（减少IO），池技术等也广泛应用在实践中，有效的提升了系统并发能力。
    为了提升并发能力，逻辑后端对请求的处理，一般会用到生产者-消费者多线程模型，即I/O线程负责网络IO，协议编解码，网络字节流被解码后产生的协议对象，
        会被包装成task投入到task queue，然后worker线程会从该队列取出task执行，有些系统会用多进程而非多线程，通过共享存储，维护2个方向的shm queue，
        一个input q，一个output q，为了提高并发度，有时候会引入协程，协程是用户线程态的多执行流，它的切换成本更低，通常有更好的调度效率。
    另外，构建漏斗型业务或者系统，从客户端请求到接入层，到逻辑层，到DB层，层层递减，过滤掉请求，Fail Fast（尽早发现尽早过滤），嘴大屁眼小，哈哈。
    漏斗型系统不仅仅是一个技术模型，它也可以是一个产品思维，配合产品的用户分流，逻辑分离，可以构建全方位的立体模型。
```