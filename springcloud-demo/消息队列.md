# 消息队列学习
## 消息队列基础
### 消息队列的使用场景
[消息队列的使用场景](https://blog.csdn.net/fygu18/article/details/80863596)
[什么是消息中间件？主要作用是什么？](https://www.cnblogs.com/lm970585581/p/13590761.html)
```markdown
1.异步处理
    如用户注册后，需要发注册邮件和注册短信。传统的做法有两种：串行的方式和并行方式
    注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。
    因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍！
2.应用解耦
    场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。
    传统模式的缺点：
    假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合。
    引入消息队列后
    订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功
    库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作
    假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。
3.流量削锋
    应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。
    可以控制活动的人数，可以缓解短时间内高流量压垮应用。
4.日志处理
    是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题
5.消息通讯
    消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。
    比如说交易系统下订单后可以通过Kafka去通知其他的系统如广告系统、推荐系统等
    Kafka采用发布订阅模型就是设计模式中的观察者模型
    发布订阅模型（Pub-Sub）使用主题（Topic）作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。
使用MQ之后的问题：
    当然使用了消息队列，会增加系统的复杂性，一致性延迟，可用性降低等问题。
    可用性降低是指系统可用性降低，如果MQ挂了，那么肯定会影响到整个系统了。因为上下游系统可能都会与MQ交互。
```
### Kafka、ActiveMQ、RabbitMQ、RocketMQ 有什么优缺点
```markdown
建议：中小型公司 RabbitMQ 大公司：RocketMQ 大数据实时计算：Kafka
```
### 1.如何保证消息不被重复消费(怎么保证幂等)
```markdown
为什么会重复消费?
    生产者：也就是客户端，可能会重复推送一条数据到MQ中。有可能是客户端超时重复推送，也有可能是网络比较慢客户端重复推送了数据到MQ中。
    MQ：消费者消费完了一条数据，发送ACK信息表示消费成功时，这时候，MQ突然挂了，导致MQ以为消费者还未消费该条消息，MQ恢复后再次推送了该条消息，导致重复消费。
    消费者：与上面MQ挂掉情况类似，消费者已经消费完了一条消息，正准备给MQ发送ACK消息但还未发送时，这时候消费者挂了，服务重启后MQ以为消费者还没有消费该条消息，再次推送该条消息。
怎么处理重复消费#
    每个消息都带一个唯一的消息id。消费端保证不重复消费就可以了，即使生产端产生了重复的数据，当然生产端也最好控制下重复数据。
消费端保证不重复消费：
    通常方法都是存储消费了的消息，然后判断消息是否存在。
    1.先保存在查询
        每次保存数据前，先查询下，不存在就插入。这种是并发不高的情况下可以使用。
    2.数据库添加唯一约束条件
        比如唯一索引
    3.增加一个消息表
    已经消费的消息，把消息id插入到消息表里面。
    为了保证高并发，消息表可以用Redis来存。
```
### 2.如何处理消息丢失的问题
```markdown
消息丢失的原因#
    生产者：生产者推送消息到MQ中，但是网络出现了故障，比如网络超时，网络抖动，导致消息没有推送到MQ中，在网络中丢失了。又或者推送到MQ中了，但是这时候MQ内部出错导致消息丢失。
    MQ：MQ自己内部发生了错误，导致消息丢失。
    消费者：有时处理消息的消费者处理不当，还没等消息处理完，就给MQ发送确认信息，但是这时候消费者自身出问题，挂了，确认消息已经发送给MQ告诉MQ自己已经消费完了，导致消息丢失。
如何保证消息不丢失呢？如何保证消息可靠性传输。
    整个消息从生产到消费一般分为三个阶段：生产者-生产阶段，MQ-存储阶段，消费者-消费阶段
    1 生产者-生产阶段
    在这个阶段，一般通过请求确认机制，来保证消息可靠性传输。 与TCP/IP协议里ACK机制有点像。
    客户端发送消息到消息队列，消息队列给客户端一个确认响应，表示消息已经收到，客户端收到响应，表示一次正常消息发送完毕。
    2 MQ-存储阶段
    消息队列给客户端发送确认消息。存储完成后，才发送确认消息。
    3 消费者-消费阶段
    跟生产阶段相同，消费完了，给消息队列发送确认消息。
```
### 3.如何保证消息的顺序性
```markdown
在消息队列中，消息的顺序性需要3方面来保证：
1、生产者发送消息时要保证顺序
2、消息被消息队列存储时要保持和发送的顺序一致
3、消息被消费时保持和存储的顺序一致
生产者：发送时要求用户在同一个线程中采用同步的方式发送。
消息队列：存储保持和发送的顺序一致。一般是在一个分区中保持顺序性。
消费者：一个分区的消息由一个线程来处理消费消息。
```

## kafka
[Apache Kafka源码](https://github.com/apache/kafka)
[参考书籍：Kafka权威指南](https://www.baidu.com)
[源码分析 Kafka](https://www.cnblogs.com/dingwpmz/category/1624446.html)
### Kafka简介
```markdown
Apache Kafka是由Apache开源的消息引擎系统。逐渐演变成现在分布式的流处理平台。
    分布式消息中间件，分布式日志处理中间件。
关键功能：
    发布和订阅记录流，类似于消息队列或者企业消息传递系统
    以容错的持久方式存储记录流
    处理记录流
    很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据。
```
### Kafka安装配置
[Kafka常用命令](https://blog.csdn.net/qq_33689414/article/details/81046502)
```markdown
- 安装zookeeper
tar -zxvf zookeeper-3.4.14.tar.gz -C /usr/local/
- 安装目录 /usr/local/zookeeper
- 数据目录 /var/lib/zookeeper
mv zookeeper-3.4.14 zookeeper
cd /zookeeper/conf/kafka
cp zoo_sample.cfg zoo.cfg
vi zoo.cfg
dataDir=/var/lib/zookeeper
- 启动
./bin/zkServer.sh start
- 安装 kafka
tar -zxvf kafka_2.11-2.1.1.tgz -C /usr/local/
mv kafka_2.11-2.1.1.tgz kafka
mkdir /tmp/kafka-logs   #kafka日志文件目录
-  启动kafka
 cd kafka
 ./bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
- 验证kafka安装
- 配置broker配置
```
### kafka基本架构
[深入分析Kafka架构（一）：工作流程、存储机制、分区策略](https://blog.csdn.net/qq_26803795/article/details/105489068)
[深入分析Kafka架构（二）：数据可靠性、故障处理](https://blog.csdn.net/qq_26803795/article/details/105515161)
[深入分析Kafka架构（三）：消费者消费方式、三种分区分配策略、offset维护](https://blog.csdn.net/qq_26803795/article/details/105562691)
[深入分析Kafka工作流程、存储机制、分区策略](https://ropledata.blog.csdn.net/article/details/109265052)
```markdown
Broker：一个kafka节点就是一个broker，多个broker组成一个kafka集群。一个broker可以是一个单机器kafka服务器。
Topic：存放消息的主题，相当于一个队列。可以理解为存放消息的分类，比如你可以有前端日志的Topic，后端日志的Topic。可以理解为MySQL里的表。
Partition：一个topic可以划分为多个partition，每个partition都是一个有序队列。把topic主题中的消息进行分拆，均摊到kafka集群中不同机器上。partition是topic的进一步拆分。
Replica：副本消息。kafka可以以partition为单位，保存多个副本，分散在不同的broker上。副本数是可以设置的。
Segment: 一个Partition被切分为多个Segment，每个Segment包含索引文件和数据文件。
Message：kafka里最基本消息单元。
一个kafka集群可以由多个broker组成，每个broker是一个节点，你创建一个topic，这个topic可以划分为多个partition，每个partition可以存储在不同的broker上，每个partition存放一部分数据。
一些kafka术语：
    主题（Topic）：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至是每类数据都创建专属的主题。
    生产者（Producer）：向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息。
    消费者（Consumer）：订阅这些主题消息的客户端应用程序就被称为消费者（Consumer），消费者也能够同时订阅多个主题的消息。
    客户端（Clients）：把生产者和消费者统称为客户端（Clients）。可以同时运行多个生产者和消费者实例，这些实例会不断地向Kafka集群中的多个主题生产和消费消息。
    服务器端：Kafka的服务器端由被称为Broker的服务进程构成，即一个Kafka集群由多个Broker组成，Broker负责接收和处理客户端发送过来的请求，以及对消息进行持久化。
    备份机制（Replication）：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在Kafka中被称为副本（Replica）。
        Kafka定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。
        副本的工作机制：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。
    分区（Partitioning）：Kafka中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。
    消息位移：Offset表示分区中每条消息的位置信息，是一个单调递增且不变的值。
    消费者位移：Consumer Offset表征消费者消费进度，每个消费者都有自己的消费者位移。
    消费者组：Consumer Group多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
    重平衡：Rebalance消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance是Kafka消费者端实现高可用的重要手段。
    Kafka的消息层次都分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），而日志项才是真正封装消息的地方。
    Kafka底层的消息日志由一系列消息集合日志项组成。Kafka通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。
```
### 1.Kafka是否可以脱离zookeeper使用
```markdown
Kafka不能脱离zookeeper单独使用，因为kafka使用zookeeper管理和协调kafka的节点服务器。
```
### 2.kafka有几种数控保留策略
```markdown
kafka有两种数据保留策略：按照过期时间保留和按照存储的消息大小保留。
```
### Kafka的文件存储机制
```markdown
Kafka中消息是以topic进行分类的，生产者通过topic向Kafka broker发送消息，消费者通过topic读取数据。
    然而topic在物理层面又能以partition为分组，一个topic可以分成若干个partition。partition还可以细分为segment，
    一个partition物理上由多个segment组成，segment文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为segment索引文件和数据文件。
    这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。
```
### Kafka如何保证可靠性
```markdown
如果我们要往Kafka对应的主题发送消息，我们需要通过Producer完成。Kafka主题对应了多个分区，每个分区下面又对应了多个副本；
    为了让用户设置数据可靠性，Kafka在Producer里面提供了消息确认机制。也就是说我们可以通过配置来决定消息发送到对应分区的几个副本才算消息发送成功。
    可以在定义Producer时通过acks参数指定。这个参数支持以下三种值：
    1.acks=0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka。
        在这种情况下还是有可能发生错误，比如发送的对象无能被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。
        在acks=0模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式，一定会丢失一些消息。
    2.acks=1：意味若Leader在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。
        在这个模式下，如果发生正常的Leader选举，生产者会在选举时收到一个LeaderNotAvailableException异常，如果生产者能恰当地处理这个错误，
        它会重试发送悄息，最终消息会安全到达新的Leader那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入Leader，但在消息被复制到follower副本之前Leader发生崩溃。
    3.acks=all（这个和request.required.acks=-1 含义一样）：意味着Leader在返回确认或错误响应之前，会等待所有同步副本都收到悄息。
        如果和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。
        不过这也是最慢的做法，因为生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。
```
### Kafka消息是采用Pull模式，还是Push模式
```markdown
Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。
    在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：
        producer将消息推送到broker，consumer从broker拉取消息。
    push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。
    最终Kafka还是选取了传统的pull模式。
    Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。
    Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。
    为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达。
```
### Kafka是如何实现高吞吐率的
```markdown
1.顺序读写：kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
2.零拷贝：跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”
3.文件分段：kafka的队列topic被分为了多个区partition，每个partition又分为多个段segment，所以一个队列中的消息实际上是保存在N多个片段文件中
4.批量发送：Kafka允许进行批量发送消息，先将消息缓存在内存中，然后一次请求批量发送出去
5.数据压缩：Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩
```
### Kafka判断一个节点还活着的两个条件
```markdown
1.节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接
2.如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久
```
### Kafka生产者消费者
[kafka实战篇（一）：Producer消息发送实战](https://blog.csdn.net/qq_26803795/article/details/105682276)
[kafka实战篇（二）：消息消费实战](https://blog.csdn.net/qq_26803795/article/details/105731900)
#### Kafka生产者
![image-20201123213740535](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201123213740.png)
```markdown
根据KafkaProducer类上的注释上来看KafkaProducer具有如下特征：
    1.KafkaProducer是线程安全的，可以被多个线程交叉使用。
    2.KafkaProducer内部包含一个缓存池，存放待发送消息，即ProducerRecord队列，与此同时会开启一个IO线程将ProducerRecord对象发送到Kafka集群。
    3.KafkaProducer的消息发送API send方法是异步，只负责将待发送消息ProducerRecord发送到缓存区中，立即返回，并返回一个结果凭证Future。
    4.acks用来定义消息“已提交”的条件(标准)，就是Broker端向客户端承偌已提交的条件。0，all,1
    .....
发送消息主要的三种方式
	- 发送并忘记，
    - 同步发送，
    - 异步发送。
```
#### Kafka生产者发送消息
```java
// org.apache.kafka.clients
import java.util.Properties;
public class Demo{

    //创建一个生产者
    // 新建 Properties 对象。
    private Properties kafkaProps = new Properties();
    kafkaProps.put("bootstrap.servers","broker1:9092,broker2:9092")
    // 因为我们打算把键和值定义成字符串类型，所以使用内置的 StringSerializer
    kafkaProps.put("key.serializer","org.apache.kafka.common.serializaion.StringSerializer");
    kafkaProps.put("value.serializer","org.apache.kafka.common.serializaion.StringSerializer");
    // 在这里我们创建了一个新的生产者对象，并为键和值设置了恰当的类型，然后把Properties对象传给它。
    producer = new KafkaProducer<String,String>(kafkaPorps);


    //发送消息到Kafka,并不关心消息是否正常到达
    ProducerRecord<String ,String > record = new ProducerRecord<>("CustomerCountry","Precision Products","France");
    try{
        producer.send(recird);
    }catch(Exception e;){
        e.printStackTrace();
    }
    //同步发送消息到Kafka,使用send()方法发送消息，它会返回一个Future对象，调用get()方法进行等待，就可以指定消息是否发送成功。
    ProducerRecord<String ,String > record = new ProducerRecord<>("CustomerCountry","Precision Products","France");
    try{
        producer.send(recird).get();
    }catch(Exception e;){
        e.printStackTrace();
    }
    //异步发送消息到Kafka，调用send()，并指定一个回调函数，服务器在返回响应时调用该函数。
    private class DemoProducerCallback implements Callback{
        @Override
        public void onCompletion(RecordMetdata ercordMetadata,Excetion e){
            if(e != null){
                e.printStackTrace();
            }
        }
    }
    ProducerRecord<String ,String > record = new ProducerRecord<>("CustomerCountry","Biomedical Materials","USA");
    producer.send(record , new DemoProducerCallback(){
});
}
```
#### Kafka消费者
```markdown
Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同 个主题，每个消费者接收主题一部分分区的消息。
```
#### Kafka消费者接收消息
```java
public class KafkaConsumer{
    
}
```
### Kafka消息丢失
```markdown
Kafka到底在什么情况下才能保证消息不丢失呢？
    一句话概括，Kafka只对“已提交”的消息（committed message）做有限度的持久化保证。
    这句话里面有两个核心要素，我们一一来看。
        第一个核心要素是“已提交的消息”。什么是已提交的消息？当Kafka的若干个Broker成功地接收到一条消息并写入到日志文件后，
            它们会告诉生产者程序这条消息已成功提交。此时，这条消息在Kafka看来就正式变为“已提交”消息了。
        第二个核心要素就是“有限度的持久化保证”，也就是说Kafka不可能保证在任何情况下都做到不丢失消息。
    总结一下，Kafka是能做到不丢失消息的，只不过这些消息必须是已提交的消息，而且还要满足一定的条件。
“消息丢失”案例:
    - 案例 1：生产者程序丢失数据。
        目前Kafka Producer是异步发送消息的，也就是说如果你调用的是producer.send(msg) 这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。
        解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用producer.send(msg)，而要使用producer.send(msg, callback)。
        callback（回调）能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。
    - 案例 2：消费者程序丢失数据
        Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。Consumer程序有个“位移”的概念，表示的是这个Consumer当前消费到的Topic分区的位置。
        Kafka中Consumer端的消息丢失就是这么一回事。
        要对抗这种消息丢失，办法很简单：维持先消费消息（阅读），再更新位移（书签）的顺序即可。这样就能最大限度地保证消息不丢失。
        对于Kafka而言，这就好比Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。
        假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。\
        解决方案也很简单：如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移。
最佳实践:
    - 1.不要使用producer.send(msg)，而要使用producer.send(msg, callback)。记住，一定要使用带有回调通知的send方法。
    - 2.设置acks = all。acks是Producer的一个参数，代表了你对“已提交”消息的定义。如果设置成all，则表明所有副本Broker都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提交”定义。
    - 3.设置retries为一个较大的值。retries同样是Producer的参数，对应前面提到的Producer自动重试。
        当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了retries>0的Producer能够自动重试消息发送，避免消息丢失。
    - 4.设置unclean.leader.election.enable=false。这是Broker端的参数，它控制的是哪些Broker有资格竞选分区的Leader。
        如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失。故一般都要将该参数设置成false，即不允许这种情况的发生。
    - 5.设置replication.factor>=3。Broker端的参数。其实这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余。
    - 6.设置min.insync.replicas>1。Broker端参数，控制的是消息至少要被写入到多少个副本才算是“已提交”。设置成大于1可以提升消息持久性。在实际环境中千万不要使用默认值1。
    - 7.确保replication.factor>min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。
        我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成replication.factor=min.insync.replicas+1。
    - 8.确保消息消费完成再提交。Consumer端有个参数enable.auto.commit，最好把它设置成false，并采用手动提交位移的方式。
```
### Kafka拦截器
[kafka自定义拦截器｜案例实战](https://ropledata.blog.csdn.net/article/details/105768429)
```markdown
Kafka拦截器分为生产者拦截器和消费者拦截器。
    生产者拦截器允许你在发送消息前以及消息提交成功后植入你的拦截器逻辑；
    消费者拦截器支持在消费消息前以及提交位移后编写特定逻辑。
Kafka拦截器的设置方法是通过参数配置完成的。生产者和消费者两端有一个相同的参数，名字叫interceptor.classes，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。
一定要注意的是，指定拦截器类时要指定它们的全限定名，即full qualified name。通俗点说就是要把完整包名也加上，不要只有一个类名在那里，并且还要保证你的Producer程序能够正确加载你的拦截器类。
典型使用场景:
    Kafka拦截器可以应用于包括客户端监控、端到端系统性能检测、消息审计等多种功能在内的场景。
```


## RocketMQ
【随笔分类 - RocketMQ】[RocketMQ](https://www.cnblogs.com/a526583280/category/1516277.html)  
[MQ消息队列](https://www.cnblogs.com/qdhxhz/category/1221076.html)
[【Rocketmq】通过 docker 快速搭建 rocketmq 环境](https://www.cnblogs.com/kiwifly/p/11546008.html)
[今日头条在消息服务平台和容灾体系建设方面的实践与思考](https://www.cnblogs.com/lishangzhi/p/11773756.html)
[SpringBoot如何优雅的使用RocketMQ](https://www.cnblogs.com/SimpleWu/p/12112351.html)
[2小时轻松搞定RocketMQ|传智播客](https://www.bilibili.com/video/av50735307?from=search&seid=9244426847363551201)
[RocketMQ延迟消息的代码实战及原理分析](https://www.cnblogs.com/heihaozi/p/13259125.html)
[Kafka、RabbitMQ、RocketMQ消息中间件的对比 —— 消息发送性能](http://jm.taobao.org/2016/04/01/kafka-vs-rabbitmq-vs-rocketmq-message-send-performance/)
[阿里中间件团队博客消息中间件 分类](http://jm.taobao.org/categories/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/)
[消息中间件ActiveMQ使用详解](https://www.cnblogs.com/yanfei1819/p/10615605.html)
[ActiveMQ入门系列之应用：Springboot+ActiveMQ+JavaMail实现异步邮件发送](https://www.cnblogs.com/sam-uncle/p/11032453.html)
[RabbitMQ 初探](https://www.cnblogs.com/liuzhang/p/10605701.html)
[随笔分类 - RocketMQ系列](https://www.cnblogs.com/boboooo/category/1779669.html)
[Centos7快速安装RocketMQ](https://www.cnblogs.com/ifme/p/13067735.html)
[RocketMQ事务消息学习及刨坑过程](https://www.cnblogs.com/huangying2124/p/11702761.html)
[RocketMQ入门案例](https://www.cnblogs.com/Mr-XiaoLiu/p/10620171.html)
[随笔分类 - RocketMQ](https://www.cnblogs.com/happyflyingpig/category/1137090.html)
[随笔分类 - MQ](https://www.cnblogs.com/hzmark/category/1025980.html)
[当前标签：RocketMQ](https://www.cnblogs.com/sunshine-2015/tag/RocketMQ/)
[芋道 RocketMQ源码系列](http://www.iocoder.cn/RocketMQ/install/)
[rabbitmq+sleuth+zinkip 分布式链路追踪](https://www.cnblogs.com/yychuyu/p/13324532.html)
[RocketMQ在面试中那些常见问题及答案+汇总](https://www.cnblogs.com/javazhiyin/p/13327925.html)
[RocketMQ在面试中那些常见问题及答案+汇总](https://www.cnblogs.com/javazhiyin/p/13327925.html)
[消息队列之-RocketMQ入门](https://www.cnblogs.com/feifuzeng/p/13626472.html)
[未读消息（小红点），前端与 RabbitMQ实时消息推送实践，贼简单~](https://www.cnblogs.com/chengxy-nds/p/13633337.html)
[大写的服，看完这篇你还不懂RocketMQ算我输](https://www.cnblogs.com/yinjihuan/p/13672474.html)
[SpringBoot如何优雅的使用RocketMQ](https://www.cnblogs.com/SimpleWu/p/12112351.html)
[RocketMQ消息丢失解决方案：事务消息](https://www.cnblogs.com/lm970585581/p/13809453.html)
[RocketMQ 4.7.1 环境搭建、集群、MQ整合SpringBoot](https://www.cnblogs.com/chenyanbin/p/13798952.html)
[SpringBoot 整合 RabbitMQ（包含三种消息确认机制以及消费端限流）](https://www.cnblogs.com/haixiang/p/10959551.html)

### 01.为什么要用RocketMq？
```markdown
Apache RocketMQ是一款 低延迟、高并发、高可用、高可靠的分布式消息中间件。
RocketMQ为分布式应用系统提供异步解耦和削峰填谷的能力，也具备互联网应用所需的海量消息堆积、高吞吐、可靠重试等特性。
    - 吞吐量高：单机吞吐量可达十万级
    - 可用性高：分布式架构
    - 消息可靠性高：经过参数优化配置，消息可以做到0丢失
    - 功能支持完善：MQ功能较为完善，还是分布式的，扩展性好
    - 支持10亿级别的消息堆积：不会因为堆积导致性能下降
    - 源码是java：方便我们查看源码了解它的每个环节的实现逻辑，并针对不同的业务场景进行扩展
    - 可靠性高：天生为金融互联网领域而生，对于要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况
    - 稳定性高：RoketMQ在上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验
```
### 02.RocketMq的部署架构
![RocketMQ 整体架构设计](https://img-blog.csdnimg.cn/img_convert/f31c3358070fdf51a465810e6731ad14.png)
```markdown
rocketMq的集群架构图，里面包含了四个主要部分：NameServer集群,Producer集群,Consumer集群以及Broker集群。
    NameServer担任路由消息的提供者。是一个Topic路由注册中心，主要功能是服务注册和路由信息管理。
        生产者或消费者能够通过NameServer查找各Topic相应的Broker IP列表分别进行发送消息和消费消息。
        nameServer由多个无状态的节点构成，节点之间无任何信息同步broker会定期向NameServer以发送心跳包的方式，轮询向所有NameServer注册以下元数据信息：
            1）broker的基本信息（ip port等）
            2）主题topic的地址信息
            3）broker集群信息
            4）存活的broker信息
            5）filter 过滤器
        也就是说，每个NameServer注册的信息都是一样的，而且是当前系统中的所有broker的元数据信息
    Producer负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要
    Broker，消息中转角色，负责存储消息、转发消息。在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备
    Consumer负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费
Topic：消息主题，用于将一类的消息进行归类，比如订单主题，就是所有订单相关的消息都可以由这个主题去承载，生产者向这个主题发送消息。
Queue 消息队列：组成Topic的最小单元，默认情况下一个Topic会对于多个Queue，Topic是逻辑概念，Queue是物理存储，在Consumer消费Topic消息时底层实时拉取Queue的消息。
Producer 生产者：负责生产消息并发送消息到 Topic 的角色。
Consumer 消费者：负责从 Topic 接收并消费消息 的角色。
Message 消息：生产者向 Topic 发送的内容，会被消费者消费。
消息属性：生产者发送的时候可以为消息自定义一些业务相关的属性，比如 Message Key 和 Tag 等。
Group：一类生产者或消费者，这类生产者或消费者通常生产或消费同一类消息，且消息发布或订阅的逻辑一致。
ProducerGroup：同一类Producer的集合。发送同一类消息并且发送逻辑一致。
ConsumerGroup：同一类Consumer的集合。消费同一类消息并且消费逻辑一致。
```
### 03.部署类型和特点
```markdown
RocketMQ有4种部署类型
1）单Master
    单机模式, 即只有一个Broker, 如果Broker宕机了, 会导致RocketMQ服务不可用, 不推荐使用
2）多Master模式
    组成一个集群, 集群每个节点都是Master节点, 配置简单, 性能也是最高, 某节点宕机重启不会影响RocketMQ服务
    缺点：如果某个节点宕机了, 会导致该节点存在未被消费的消息在节点恢复之前不能被消费
3）多Master多Slave模式，异步复制
    每个Master配置一个Slave, 多对Master-Slave, Master与Slave消息采用异步复制方式, 主从消息一致只会有毫秒级的延迟
    优点是弥补了多Master模式（无slave）下节点宕机后在恢复前不可订阅的问题。在Master宕机后, 消费者还可以从Slave节点进行消费。
    采用异步模式复制，提升了一定的吞吐量。总结一句就是，采用多Master多Slave模式，异步复制模式进行部署，系统将会有较低的延迟和较高的吞吐量
    缺点就是如果Master宕机, 磁盘损坏的情况下, 如果没有及时将消息复制到Slave, 会导致有少量消息丢失
4）多Master多Slave模式，同步双写
    与多Master多Slave模式，异步复制方式基本一致，唯一不同的是消息复制采用同步方式，只有master和slave都写成功以后，才会向客户端返回成功
    优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高
    缺点就是会降低消息写入的效率，并影响系统的吞吐量
    实际部署中，一般会根据业务场景的所需要的性能和消息可靠性等方面来选择后两种
```
### 04.安装部署RocketMQ
```markdown
1.上传RocketMQ安装包到Linux服务器(需要先安装JDK和Maven) 使用源码安装的方式安装
> unzip rocketmq-all-4.6.0-source-release.zip # 解压安装包
> mv rocketmq-all-4.6.0-source-release rocketmq # 对解压文件重命名
> cd rocketmq # 移动到解压重命名的文件中
> mvn -Prelease-all -DskipTests clean install -U # maven编译打包**打包要好久，可以考虑寻找其他的安装方式**
```
### 05.rocketmq保证高可用性
```markdown
1）集群化部署NameServer。Broker集群会将所有的broker基本信息、topic信息以及两者之间的映射关系，轮询存储在每个NameServer中（也就是说每个NameServer存储的信息完全一样）。
    因此，NameServer集群化，不会因为其中的一两台服务器挂掉，而影响整个架构的消息发送与接收；
2）集群化部署多broker。producer发送消息到broker的master，若当前的master挂掉，则会自动切换到其他的master
    cosumer默认会访问broker的master节点获取消息，那么master节点挂了之后，该怎么办呢？它就会自动切换到同一个broker组的slave节点进行消费
    那么你肯定会想到会有这样一个问题：consumer要是直接消费slave节点，那master在宕机前没有来得及把消息同步到slave节点，那这个时候，不就会出现消费者不就取不到消息的情况了？
    这样，就引出了下一个措施，来保证消息的高可用性
3）设置同步复制
    前面已经提到，消息发送到broker的master节点上，master需要将消息复制到slave节点上，rocketmq提供两种复制方式：同步复制和异步复制
    异步复制，就是消息发送到master节点，只要master写成功，就直接向客户端返回成功，后续再异步写入slave节点
    同步复制，就是等master和slave都成功写入内存之后，才会向客户端返回成功
    那么，要保证高可用性，就需要将复制方式配置成同步复制，这样即使master节点挂了，slave上也有当前master的所有备份数据，那么不仅保证消费者消费到的消息是完整的，
    并且当master节点恢复之后，也容易恢复消息数据，在master的配置文件中直接配置brokerRole：SYNC_MASTER即可。
```
### 06.rocketmq的工作流程
```markdown
RocketMq的工作流程如下：
1）首先启动NameServer。NameServer启动后监听端口，等待Broker、Producer以及Consumer连上来
2）启动Broker。启动之后，会跟所有的NameServer建立并保持一个长连接，定时发送心跳包。心跳包中包含当前Broker信息(ip、port等)、Topic信息以及Borker与Topic的映射关系
3）创建Topic。创建时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic
4）Producer发送消息。启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic所在的Broker；然后从队列列表中轮询选择一个队列，与队列所在的Broker建立长连接，进行消息的发送
5）Consumer消费消息。跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，进行消息的消费
```
### 07.RocketMq使用哪种方式消费消息
```markdown
RocketMq提供两种方式：pull和push进行消息的消费
而RocketMq的push方式，本质上也是采用pull的方式进行实现的。也就是说这两种方式本质上都是采用consumer轮询从broker拉取消息的
push方式里，consumer把轮询过程封装了一层，并注册了MessageListener监听器。当轮询取到消息后，便唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉好像消息是被推送过来的
其实想想，消息统一都发到了broker，而broker又不会主动去push消息，那么消息肯定都是需要消费者主动去拉的喽~
```
### 08.RocketMq负载均衡
```markdown
1）producer发送消息的负载均衡：默认会轮询向Topic的所有queue发送消息，以达到消息平均落到不同的queue上；而由于queue可以落在不同的broker上，就可以发到不同broker上（当然也可以指定发送到某个特定的queue上）
2）consumer订阅消息的负载均衡：假设有5个队列，两个消费者，则第一个消费者消费3个队列，第二个则消费2个队列，以达到平均消费的效果。
    而需要注意的是，当consumer的数量大于队列的数量的话，根据rocketMq的机制，多出来的队列不会去消费数据，因此建议consumer的数量小于或者等于queue的数量，避免不必要的浪费
```
### 09.RocketMq的存储机制
```markdown
RocketMq采用文件系统进行消息的存储，相对于ActiveMq采用关系型数据库进行存储的方式就更直接，性能更高了
RocketMq与Kafka在写消息与发送消息上，继续沿用了Kafka的这两个方面：顺序写和零拷贝
1）顺序写
我们知道，操作系统每次从磁盘读写数据的时候，都需要找到数据在磁盘上的地址，再进行读写。而如果是机械硬盘，寻址需要的时间往往会比较长
而一般来说，如果把数据存储在内存上面，少了寻址的过程，性能会好很多；但Kafka 的数据存储在磁盘上面，依然性能很好，这是为什么呢？
这是因为，Kafka采用的是顺序写，直接追加数据到末尾。实际上，磁盘顺序写的性能极高，在磁盘个数一定，转数一定的情况下，基本和内存速度一致
因此，磁盘的顺序写这一机制，极大地保证了Kafka本身的性能
2）零拷贝
比如：读取文件，再用socket发送出去这一过程
buffer = File.read
Socket.send(buffer)
传统方式实现：
先读取、再发送，实际会经过以下四次复制
1、将磁盘文件，读取到操作系统内核缓冲区Read Buffer
2、将内核缓冲区的数据，复制到应用程序缓冲区Application Buffer
3、将应用程序缓冲区Application Buffer中的数据，复制到socket网络发送缓冲区
4、将Socket buffer的数据，复制到网卡，由网卡进行网络传输
小结：RocketMq采用文件系统存储消息，并采用顺序写写入消息，使用零拷贝发送消息，极大得保证了RocketMq的性能
```
### 10.RocketMq的存储结构
```markdown
CommitLog-存储所有的消息元数据，包括Topic、QueueId以及message
CosumerQueue-消费逻辑队列：存储消息在CommitLog的offset
IndexFile-索引文件：存储消息的key和时间戳等信息，使得RocketMq可以采用key和时间区间来查询消息
也就是说，rocketMq将消息均存储在CommitLog中，并分别提供了CosumerQueue和IndexFile两个索引，来快速检索消息
```
### 11.RocketMq进行消息的去重
```markdown
RocketMq本身并不保证消息不重复，这样肯定会因为每次的判断，导致性能打折扣，所以它将去重操作直接放在了消费端：
1）消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样
2）还可以建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费
```
### 12.RocketMq性能比较高的原因
```markdown
RocketMq采用文件系统存储消息，采用顺序写的方式写入消息，使用零拷贝发送消息，这三者的结合极大地保证了RocketMq的性能。
```
### RocketMQ消息类型
```markdown
RocketMQ 支持丰富的消息类型，可以满足多场景的业务需求。不同的消息有不同的应用场景，下面为大家介绍常用的四种消息类型。
    普通消息是指 RocketMQ 中无特性的消息。当没有特殊的业务场景，使用普通消息就够了。如果有特殊的场景，就可以使用特殊的消息类型，比如顺序，事务等。
    同步发送：消息发送方发送出去一条消息，会同步得到服务端返回的结果。
    异步发送：消息发送方发出去一条消息，不用等待服务端返回结果，可以接着发送下一条消息。发送方可以通过回调接口接收服务端响应，并处理响应结果。
    单向发送：消息发送方只负责发送消息，发送出去后就不管了，这种方式发送速度非常快，存在丢失消息的风险。
    顺序消息：是指生产者按照一定的先后顺序发布消息；消费者按照既定的先后顺序订阅消息，即先发布的消息一定会先被消费者接收到。
    定时消息：是指消息具备定时发送的功能，当消息发送到服务端后，不会立即投递给消费者。而是要等到消息指定的时间后才会投递给消费者进行消费。
    事务消息：RocketMQ 提供类似 X/Open XA 的分布式事务功能，通过 RocketMQ 事务消息能达到分布式事务的最终一致。
```
###