# ElasticSearch学习
[参考视频1：详细ElasticSearch技术讲解](https://www.bilibili.com/video/av66259861)
[参考视频2：ElasticSearch6入门教程](E:\学习视频\004.ElasticSearch6入门教程（62集）)
[ElasticSearch官网](https://www.elastic.co/cn/)
[elasticsearch下载太慢在国内](https://blog.csdn.net/weixin_37281289/article/details/101483434)

## ES基础学习使用
[**参考博客：ElasticSearch学习**](https://www.cnblogs.com/shoufeng/category/1332134.html)
[**当前标签：elasticsearch**](https://www.cnblogs.com/huangying2124/tag/elasticsearch/default.html)
### Elasticsearch介绍和应用场景
```markdown
Elasticsearch是一个实时分布式搜索和分析引擎。它用于全文搜索、结构化搜索、分析。
全文检索：将非结构化数据中的一部分信息提取出来,重新组织,使其变得有一定结构,然后对此有一定结构的数据进行搜索,从而达到搜索相对较快的目的。
结构化检索：我想搜索商品分类为日化用品的商品都有哪些，select * from products where category_id='日化用品'
数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些
```
### ElasticSearch简介
[ElasticSearch简介](https://www.cnblogs.com/haixiang/p/11078875.html)
```markdown
Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许您快速，近实时地存储，搜索和分析大量数据。
它通常用作底层引擎、技术，为具有复杂搜索功能和要求的应用程序提供支持。
Elasticsearch是通过Lucene的倒排索引技术实现比关系型数据库更快的过滤。特别是它对多条件的过滤支持非常好。
Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTfulAPI来隐藏Lucene的复杂性，从而让全文搜索变得简单。
优点
    - 具备横向可扩展性：只需要增加一台服务器，做些配置，启动 ES 进程就可以快速并入集群。'
    - 分片机制：同一个索引分成多个分片(sharding)，类似于 redis 中的分片，采取分而治之的思想来更好地解决问题。
    - 高可用：提供复制机制，一个分片可以设置多个复制，使得某台服务器宕机的话，集群依旧可以正常运行，并会把丢失的复制恢复到其它可用节点上。
缺点
    节点数据的一致性问题：其默认的机制是通过多播机制，同步元数据信息，但是在比较繁忙的集群中，可能会由于网络的阻塞，
    或者节点处理能力达到饱和导致各节点元数据不一致——也就是所谓的脑裂问题，这样会使集群处于不一致状态。
    目前并没有一个彻底的解决方案来解决这个问题，但是可以通过将工作节点与元数据节点分开的部署方案来缓解这种情况。
    没有细粒度的权限管理，没有像MySQL那样的分各种用户，每个用户又有不同的权限。
解决的问题
    - 更快的在大量数据中检索相关数据，性能远优于传统数据库
    - 结合分词器，根据关键词返回统计结果
```
### 七个生产案例了解应用场景和优势
[七个生产案例告诉你BATJ为何选择ElasticSearch！应用场景和优势！](https://www.cnblogs.com/liuyanling/p/13023251.html)
```markdown
ElasticSearch的应用场景和优势，包括：
    - 日志实时分析
    - 搜索服务
    - 数据分析
    - 数据监控
    - 查询服务
    - 后端存储
ElasticSearch在腾讯的应用
ElasticSearch在腾讯的应用非常广泛，主要有三：日志实时分析场景、搜索服务、时序数据分析。
    搜索服务：例如像腾讯文档基于ES做全文检索，电商客户拼多多、蘑菇街等大量的商品搜索都是基ES。
    日志分析：这是ES应用最广泛的领域，支持全栈的日志分析，包括各种应用日志、数据库日志、用户行为日志、网络数据、安全数据等等。
        ES拥有一套完整的日志解决方案，可以秒级实现从采集到展示。
    时序分析：典型的场景是监控数据分析，比如云监控，整个腾讯云的监控都是基于ES的。
        此外还包括物联网场景，也有大量的时序数据。时序数据的特点是写入吞吐量特别高，ES支持的同时也提供了丰富的多维统计分析算子。
ElasticSearch在京东的应用
    通过京东的案例，聊一聊ES在查询、检索、数据分析方面的应用场景
    - 补充关系型数据库的结构化数据查询
        主要应用的业务是商品、促销、优惠券、订单、收银台、物流、对账、评论等大数据量查询。此场景的核心诉求是高性能、稳定性和高可用性，
        部分场景会有检索要求，通常用于加速关系型数据库，业务系统通过 binlog 同步或业务双写完成数据同步。
    - 全文检索功能
        主要的应用场景是应用、安全、风控、交易等操作日志，以及京东部分品类商品搜索。此类日志化场景对写要求很高，查询性能及高可用等要求相对较低，大的业务写会达到数千万/秒，存储以PB为单位来计算。
        这些场景对磁盘、内存有比较高的要求，因此，京东也做了相应优化，用于减少内存消耗，提升磁盘整体使用率，使用更廉价的磁盘来降低成本等等。
    - 实时数据分析引擎，形成统计报表
        主要应用的业务是物流单的各种分析、订单数据分析、用户画像等。因为业务数据分析纬度较多，flink、storm 等
        流式分析对于某些报表场景不太适用，批处理实时性又成为问题，所以近实时分析的Elasticsearch就成为了这些业务的选择。
ElasticSearch在去哪儿的应用
    - Elasticsearch分布式搜索储存集群的引入，就是为了解决订单数据的存储与搜索的问题。
    - 对订单模型进行抽象和分类，将常用搜索字段和基础属性字段剥离。DB做分库分表，存储订单详情；Elasticsearch存储搜素字段。
什么时候应该用ElasticSearch?
1、典型搜索场景：闭着眼用它！
2、典型日志分析场景：闭着眼用它！
3、关系型数据库查询有瓶颈：考虑下用它！为啥是考虑？ES的优点在于查询，然而实践证明，在被作为数据库来使用，即写完马上查询会有延迟。
4、数据分析场景：考虑下用它！为啥是考虑？简单通用的场景需求可以大规模使用，但在特定业务场景领域，还是要选择更加专业的数据产品，
    如复杂聚合，ClickHouse相比 Elasticserach 做亿级别数据深度聚合需求会更加合适。
ElasticSearch有什么优势呢？
1、很简便的横向扩容，分布式的架构，可以轻松地对资源进行横向纵向扩缩容，可以满足不同数据量级及查询场景对硬件资源的需求。
    能由数百台到万台机器搭建满足PB级的快速搜索，也能搭建单机版服务小公司。
2、查询速度快：ES底层采用Lucene作为搜索引擎，并在此之上做了多重优化，保证了用户对数据查询数据的需求。
    可"代替"传统关系型数据库，也可用于复杂数据分析，海量数据的近实时处理等。
3、相关性高：ES内部提供了完善的评分机制，会根据分词出现的频次等信息对文档进行相关性排序，保证相关性越高的文档排序越靠前。
    另外还提供了包括模糊查询，前缀查询，通配符查询等在内的多种查询手段，帮助用户快速高效地进行检索。
4、功能点多但使用比较简便，开箱即用，性能优化比较简单
5、生态圈丰富，社区活跃，适配多种工具。如下图，处理日志和输出到Elasticsearch，您可以使用日志记录工具，如Logstash（www.elastic.co/products/logstash），
    搜索和可视化界面分析这些日志，你可以使用Kibana（www.elastic.co/产品/kibana），即传说中的ELK技术栈。另外当前主流的大数据框架也几乎都支持ES，比如Flink和ES就是个完美搭档。
```
### ES的9200和9300端口区别
```markdown
9200作为Http协议，主要用于外部通讯
9300作为Tcp协议，jar之间就是通过tcp协议通讯
ES集群之间是通过9300进行通讯
```
### 1.ElasticSearch介绍
```markdown
Elasticsearch（ES）是一个基于Lucene构建的开源分布式搜索分析引擎，可以近实时的索引、检索数据。具备高可靠、易使用、社区活跃等特点，
在全文检索、日志分析、监控分析等场景具有广泛应用。
由于高可扩展性，集群可扩展至百节点规模，处理PB级数据。通过简单的RESTful API即可实现写入、查询、集群管理等操作。
除了检索，还提供丰富的统计分析功能。以及官方功能扩展包XPack满足其他需求，如数据加密、告警、机器学习等。
另外，可通过自定义插件，如COS备份、QQ分词等满足特定功能需求。
```
### 2.Elasticsearch架构与原理
[十张图带大家看懂 ES 原理 ！明白为什么说：ES 是准实时的！](https://www.cnblogs.com/liuzhihang/p/elasticsearch-5.html)
```markdown
基本概念 ：
    Cluster「集群」：由部署在多个机器的ES节点组成，以处理较大数据集和实现高可用；
    Node「节点」：机器上的ES进程，可配置不同类型的节点；
    Master Node「主节点」：用于集群选主。由其中一个节点担任主节点，负责集群元数据管理，如索引创建，节点离开加入集群等；
    Data Node「数据节点」：负责索引数据存储；
    Index「索引」：索引数据的逻辑集合，可类比关系型数据的DataBase；
    Shard「分片」：索引数据子集，通过将分片分配至集群不同节点，实现数据横向扩展。以解决单个节点CPU、内存、磁盘处理能力不足的情况；
    Primary Shard「主分片」：数据分片采用主从模式，由分片接收索引操作；
    Replica Shard「副本分片」：主分片的拷贝，以提高查询吞吐量和实现数据高可靠。主分片异常时，其中一个副本分片会自动提升为新的主分片。
内置自动发现实现 Zen discovery，当一个节点启动后，通过联系集群成员列表即可加入集群。
由其中一个节点担任主节点，用于集群元数据管理，维护分片在节点间的分配关系。当新节点加入集群后，Master节点会自动迁移部分分片至新节点，均衡集群负载。
分布式集群难免有节点故障。主节点会定期探测集群其他节点存活状态，当节点故障后，会将节点移出集群，并自动在其他节点上恢复故障节点上的分片。
主分片故障时会提升其中一个副本分片为主分片。其他节点也会探活主节点，当主节点故障后，会触发内置的类Raft协议选主，并通过设置最少候选主节点数，避免集群脑裂。
除了集群管理，索引数据读写也是我们关心的重要部分。ES采用peer-to-peer架构，每个节点保存全量分片路由信息，也就是每个节点均可以接收用户读写。

```
### 3.Elasticsearch应用场景
```markdown
ES的典型使用场景有日志分析、时序分析、全文检索等。
    1.日志实时分析场景
        日志从产生到可访问一般在10s级，相比于传统大数据解决方案的几十分钟、小时级时效性非常高。
        ES底层支持倒排索引、列存储等数据结构，使得在日志场景可以利用ES非常灵活的搜索分析能力。通过ES交互式分析能力，即使在万亿级日志的情况下，日志搜索响应时间也是秒级。
        日志处理的基本流程包含：日志采集->数据清洗->存储->可视化分析。Elastic Stack通过完整的日志解决方案，帮助用户完成对日志处理全链路管理。
            1.日志采集：通过轻量级日志采集组件FileBeat实时读取业务日志文件，发送数据至下游组件如Logstash。
            2.文本解析：利用正则解析等机制，将日志文本数据转换成结构化数据。可使用独立的Logstash服务或Elasticsearch内置的轻量级数据处理模块Ingest Pipeline，完成数据清洗和转换。
            3.数据存储：通过Elasticsearch搜索分析平台进行数据持久存储，提供全文搜索和分析能力。
            4.可视化分析：通过功能丰富的图形界面，即可对日志数据进行搜索分析，如可视化组件Kibana。
    2.时序分析场景
        时序数据是按时间顺序记录设备、系统状态变化的数据。典型的时序数据有传统的服务器监控指标数据、应用系统性能监控数据、智能硬件、工业物联网传感器数据等。
        ES提供灵活、多维度的统计分析能力，实现查看监控按照地域、业务模块等灵活的进行统计分析。
        另外，ES支持列存储、高压缩比、副本数按需调整等能力，可实现较低存储成本。最后时序数据也可通过Kibana组件轻松实现可视化。
    3.搜索服务场景
        通过ES高效倒排索引，以及自定义打分、排序能力与丰富的分词插件，实现全文检索需求。
```
### 4.ElasticSearch安装配置
[ES 02 - 安装Elasticsearch单机服务 以及常见问题的解决](https://www.cnblogs.com/shoufeng/p/9905830.html)
```markdown
1.下载，解压，重命名到/usr/local/es/目录下的elasticsearch
2.# 创建用户（Elasticsearch的启动, 必须通过专用用户elastic启动, 否则将报错。）
    useradd elastic -s /bin/bash 
    # 为该用户赋予相关操作权限
    chown -R elastic:elastic /usr/local/es
3.配置文件修改（修改${ES_HOME}/config/elasticsearch.yml文件中关于网络的配置:）
    # 大约17行, 修改集群名称, 同一个集群中此名称必须相同, 才能组成一个逻辑集群:
    cluster.name: es-cluster1
    # 大约23行, 修改节点名称, 可以设置为与主机名称相同:
    node.name: es-node1
    # 大约55行, 指定可通过外部服务器访问本地ES服务:
    network.host: 0.0.0.0
    # 并指定访问的端口号, 默认是9200, 为了防止冲突, 这里修改为9201:
    http.port: 9201
    # 如果要考虑到后期的版本升级, 可以指定ES存储索引和日志文件的路径, 否则容易出现数据丢失的情况.
    path.data: /usr/local/es/data
    path.logs: /usr/local/es/logs
    # 必须要配置一个才能启动,就是本节点名称
    cluster.initial_master_nodes: ["es-node1"]
4.启动服务
    # 切换用户
    su elastic 
    # 启动服务, -d是指在后台启动, 若不用此参数, ES将阻塞当前终端的命令输入功能, 如果强制使用, 将导致ES服务终止
    cd /usr/local/es/elasticsearch
    ./bin/elasticsearch -d 
5.验证ES服务是否可用
    1) 通过jps命令查看当前系统中运行的所有Java进程, 前提是JDK的环境变量设置OK:
    $ jps
    (2) 通过ps -ef或ps aux命令查看 - 可以查看到启动ES时的JVM参数:
    $ ps aux | grep elasticsearch
    (3) 在浏览器中查看 http://服务器ip:9201  服务器端口开启
6.关闭与重启服务
    $ ps aux | grep elasticsearch  # 查看ES进程的id
    $ kill -8 id  # 通过进程id来杀掉服务
    $ $ sh ./bin/elasticsearch -d
```
### 5.安装Kibana
[ES 04 - 安装Kibana以及常见问题的解决](https://www.cnblogs.com/shoufeng/p/9922157.html)
```markdown
1.上传，解压，重命名到/usr/local/es/kibana目录下
2.修改配置文件 kibana目录下的/config/kibana.yml配置文件
    # Kibana是个后台服务, 需要指定服务的IP地址和端口号. 默认值为5601. 
    server.port: 5601
    # 指定Kibana服务需要绑定的IP地址, 默认值为本地回环地址"localhost". 若要允许远程访问, 就需要改为本地服务器的IP地址. (127.0.0.1的作用等同于localhost, 可用ifconfig命令查看本机的IPV4地址)
    server.host: 192.168.101.206
    # 需要监控的Elasticsearch服务的地址, 默认是本地回环地址+9200端口
    elasticsearch.hosts: ["http://192.168.101.206:9201"]
    # Kibana在Elasticsearch中的索引
    kibana.index: ".kibana"
3.修改kibana文件用户chown -R elastic:elastic /usr/local/es/kibana/
4.启动kibana
    $ cd /usr/local/es/kibana
    $ su elsatic
    $ ./bin/kibana &   # 后台启动, 可退出终端
5.验证kibana启动成功
    在浏览器访问: http://192.168.101.206:5601, 出现如下界面, 说明启动成功: 【服务器端口号需要打开】
6.关闭Kibana服务
    # ps aux | grep node   # 查看node服务的进程id
    # kill -9 id
3.1 关于集群的状态status
    ① green: 所有primary shard和replica shard都已成功分配, 集群是100%可用的;
    ② yellow: 所有primary shard都已成功分配, 但至少有一个replica shard缺失. 此时集群所有功能都正常使用, 数据不会丢失, 搜索结果依然完整, 但集群的可用性减弱. —— 需要及时处理的警告.
    ③ red: 至少有一个primary shard(以及它的全部副本分片)缺失 —— 部分数据不能使用, 搜索只能返回部分数据, 而分配到这个分配上的写入请求会返回一个异常. 此时虽然可以运行部分功能, 但为了索引数据的完整性, 需要尽快修复集群.
3.2 关于集群中的节点数
使用GET _cat/nodes?v 查看当前节点数:
    ip            heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
    192.169.101.206      62          98   2    0.98    1.25     1.39 mdi       *      1UlY804
3.3 关于未分配的分片
    unassigned_shards: 已经在集群状态中存在、但在集群里又找不到的分片, 来源通常是未分配的副本. 比如: 一个有 5 分片和 1 副本的索引, 在单节点集群上就会有 5 个未分配副本分片.
    如果集群状态是red, 也会长期存在未分配分片(因为缺少主分片).
```
### 6.kibana操作使用ES
[ES 05 - 通过Kibana查看Elasticsearch集群的健康状态、节点和索引个数](https://www.cnblogs.com/shoufeng/p/9934436.html)
[ES 06 - 通过Kibana插件操作ES中的索引文档 (CRUD操作)](https://www.cnblogs.com/shoufeng/p/9941809.html)
```markdown
访问服务器上的kibana：http://192.168.101.206:5601/ 进入Dev tools
ES提供了一套_cat API, 可以查看ES中的各类数据.
1 检查集群的健康状况  GET _cat/health
2.查看集群中的节点个数 GET _cat/nodes
3 查看集群中的索引 GET _cat/indices
4 创建、删除索引
    PUT test_index?pretty  # 创建索引API: 
    DELETE test_index?pretty  # 删除索引API:
5 添加文档
    (1) 添加API: (说明: ES会自动创建PUT API中指定的index和type, 不需要提前创建;而且ES默认对document的每个field都建立倒排索引, 保证它们都可以被检索.)
        PUT index/type/id
        {
          "JSON格式的文档数据"
        }
    (2) 添加示例:
        PUT book_shop/it_book/1
        {
                    "name": "Java编程思想",
                    "author": "[美] Bruce Eckel",
                    "category": "编程语言",
                    "desc":  "Java学习必读经典,殿堂级著作！",
                    "price":  109.0,
                    "date": "2007-06-01",
                    "publisher": "机械工业出版社",
                    "tags": [ "Java", "编程语言" ]
        }
6.查询文档
    (1) 检索API: GET index/type/id
    (2) 检索示例:GET book_shop/it_book/2
7.修改文档
    1.替换文档
        (1) 替换API - 与添加API相同, 只不过文档id要存在, 此时系统将判定为修改操作:
        —— 无论文档数据是否存在修改, 对同一id的文档执行1次以上的PUT操作, 都是修改操作.
        (2) 替换示例 - 为name添加了"（第4版）"
        PUT book_shop/it_book/1
        {
            "name": "Java编程思想（第4版）",
            "author": "[美] Bruce Eckel",
            "category": "编程语言",
            "desc":  "Java学习必读经典,殿堂级著作！",
            "price":  109.0,
            "date": "2007-06-01",
            "publisher": "机械工业出版社",
            "tags": [ "Java", "编程语言" ]
        }
    2.更新文档
        (1) 更新API:
        —— 通过POST和_update, 更新文档中的特定字段(field), 其他的字段不会改动.
        注意: 与替换方式相比, 更新方式的好处: 可以更新指定文档的指定field, 未指定的field也不会丢失.
        (2) 更新示例 - 将name改为英文:
        POST book_shop/it_book/1/_update
        {
            "doc": {
                "name": "Thinking in Java(4th Edition) "
            }
        }
8.删除文档
    (1) 删除API:DELETE index/type/id
    (2) 删除示例:DELETE book_shop/it_book/1
    (4) 删除确认: 再次查看删除的文档:GET book_shop/it_book/1
```
### 7.ElasticSearch查询索引文档的6种方法
[ES 07 - Elasticsearch查询索引文档的6种方法](https://www.cnblogs.com/shoufeng/p/9952002.html)
[ElasticSearch核心概念和文档的CRUD](https://www.cnblogs.com/haixiang/p/11181711.html)
```markdown
1 Query String Search(查询串检索)
    这种方法通过HTTP请求的Query String携带查询参数, 因此得名.适用于临时性的查询请求, 比如在终端检查基础信息:
    # 检索name中包含Java的文档, 并按价格降序排序: 生产环境中很少使用, 因为请求参数都封装到Query String中, 难以构建复杂的查询.
    浏览器中：http://192.168.101.206:9201/book_shop/it_book/_search?q=name:Java&sort=price:desc
    查询结果中的各个参数的含义:
        ① took: 此次检索耗费的时间, 单位是毫秒;
        ② timed_out: 是否超出规定的检索时间, 这里没有设置, 后续会讲解此参数;
        ③ _shards: 被查询的index被分散成多个分片, 所以搜索请求会分发到所有的primary shard(或primary shard对应的某个replica shard)上, 这里显示各个分片是否查询成功的信息;
        ④ hits: 命中的文档情况, 有如下参数:
            total: 符合条件的文档总数, 即hit(命中)数;
            max_score: Lucene底层对检索到的文档的相关度的评分, 相关度越高, 说明越匹配, score的值也就越高.
            hits: 命中的所有document的详细数据.
2 Query DSL(ES特定语法检索) 在Kibana Dev Tools中
    DSL: Domain Specified Language, 特定领域的语言, 一般需要Kibana等工具配合操作.
    这种方式把查询参数构建成JSON格式的数据, 并封装到HTTP请求的Request Body(请求体)中, 可以构建各类复杂的查询语法, 功能要比Query String <Search强大很多></Search强大很多>
    (1) 查询全部商品:
        GET book_shop/it_book/_search
        {
            "query": { "match_all": {} }
        }
    (2) 查询name中包含Java的商品, 并按price降序排序:
        GET book_shop/it_book/_search
        {
            "query": {
                "match": {
                    "name": "Java"
                }
            },
            "sort": [
                { "price": "desc" }
            ]
        }
    (3) 分页查询商品 - 每页显示1条, 显示第3页:
        GET book_shop/it_book/_search
        {
            "query": { "match_all": {} },
            "from": 2,
            "size": 1
        }
    (4) 只查询商品的名称和价格:
        GET book_shop/it_book/_search
        {
            "query": {"match_all": {}},
            "_source": ["name", "price"]
        }
3 Query Filter(过滤检索)
    # 过滤查询, 比如: 查询name中包含Java, 且price不大于80元的商品:
    GET book_shop/it_book/_search
    {
        "query": {
            "bool": {
              	"must": {
                    "match": {"name": "Java"}	// name中含有Java
                },
                "filter": {
                    "range": { 
                        "price": {"lte": 80.0}	// 价格不大于80.0
                    }
                }
            }
        }
    }
4 Full Text Search(全文检索)
    (1) 查询描述信息desc中包含"Java图书"的文档, 只显示name和desc的值:
    GET book_shop/it_book/_search
    {
        "query": {
            "match": {"desc": "Java图书"}
        },
        "_source": ["name", "desc"]
    }
5 Phrase Search(短语检索)
    Full Text Search会对检索文本作分词处理, 然后从倒排索引中作匹配查询, 如果一个文档的对应field中存在任意一个分解后的词, 那么这个文档就算匹配检索条件.
    Phrase Search不会对检索串进行分词处理, 只有一个文档的对应field中包含与检索文本完全一致的内容, 该文档才算匹配检索条件, 也才能作为结果返回 —— 可以理解为全文检索场景下的部分精确匹配.
    (1) 精确查询desc中包含"Java图书"的文档:
    GET book_shop/it_book/_search
    {
        "query": {
            "match_phrase": {
                "desc": "Java图书"
            }
        },
        "_source": ["name", "desc"]
    }
6 Highlight Search(高亮检索)
    (1) 分页查询desc中包含"Java图书"的文档, 页大小为1, 显示第1页, 并对搜索条件高亮处理:
    GET book_shop/it_book/_search
    {
        "query": {
            "match": {"desc": "Java图书"}
        },
        "from": 0,
        "size": 1,
        "highlight": {
            "fields": {"desc": {}}
        },
        "_source": ["name", "desc"]
    }
```

[基于MySQLBinlog的 Elasticsearch数据同步实践](https://www.cnblogs.com/mfwtech/p/11187516.html)

[[关于Elasticsearch文档的描述以及如何操作文档的详细总结](https://www.cnblogs.com/lifengdi/p/11544169.html)]

[[【docker Elasticsearch】Rest风格的分布式开源搜索和分析引擎Elasticsearch初体验](https://www.cnblogs.com/lomtom/p/12584956.html)]

[手把手教你搭建一个Elasticsearch集群](https://www.cnblogs.com/tianyiliang/p/10291305.html)
[400+节点的 Elasticsearch 集群运维](https://www.cnblogs.com/vivotech/p/10600865.html)
### 8.ES索引的增删改查、打开、关闭
[ES 08 - 增删改查、打开、关闭Elasticsearch的索引](https://www.cnblogs.com/shoufeng/p/9961662.html)
```markdown
1 创建index（配置mapping[映射]）
    (1) 创建语法:
    如果不指定settings和mappings, 直接插入数据时, ES会根据要插入数据的类型, 自动创建相关配置 —— 功能强大, 但扩展性不够, 后续若有其他原因需要修改mappings, 会很困难.
    —— 所以创建index时, 推荐手动指定settings和mappings的相关配置. 可以参考文章: ES XX - ES的mapping的设置.
        PUT index
        {
            "settings": { ... some settings ... },
            "mappings": {
                // ES 6.x开始不再支持1个index中同时存在多个type
                "type1": { ... some mappings ... },
                "type2": { ... some mappings ... },
                ...
            }
        }
    (2) 创建示例:
        PUT address        // 关于地址(address)的索引
        {
            "settings": {
                "number_of_shards": 1,    // 默认分片数为5
                "number_of_replicas": 0   // 默认副本数为1
            },
            "mappings": {
                "province": {             // type是province(省份)
                    "properties": {
                        "name": {
                            "type": "text"  // 存储类型是text
                        },
                        "area": {
                            "type": "float"
                        }
                    }
                }
            }
        }
2 查看index
    (1) 查看示例:
        GET address
        // 也可同时查看多个索引, 类似于删除操作: 
        GET *
        GET _all
        GET *index*
        GET address,shop
        // 在6.0之前的版本中, 还可以指定返回某些指定项的结果:
        GET address/_settings,_mappings
3 修改index
    说明: Elasticsearch中的分片数(number_of_shards)只能在创建索引时设置, 无论是否添加过数据, 都不支持修改.
    修改索引的示例:
        PUT address/_settings
        {
            "number_of_replicas": 1		// 修改副本数为1
        }
4 删除index
    删除索引需要指明索引名称、别名或通配符.Elasticsearch支持同时删除多个索引, 或使用_all或通配符*删除全部索引.
    删除示例:
        DELETE address        // 删除指定索引
        DELETE index1,index2  // 删除多个索引
        DELETE index_*        // 按通配符删除以'index_'开头的索引
        DELETE _all           // 删除全部索引
    为避免_all操作误删除全部索引, 可在配置文件elasticsearch.yml中作如下配置:
    # 要求操作索引时必须指定索引的名称
    action.destructive_requires_name: true
5 打开/关闭index
    1) 操作说明:
        ① 可以打开一个已经打开/关闭的索引, 以最后一次操作为准;
        ② 可以关闭一个已经关闭/打开的索引, 以最后一次操作为准;
        ③ 关闭的索引只能查看index的配置信息, 不能对内部的索引数据进行读写操作.
    (2) 操作示例:
        // 可以使用_all打开或关闭全部索引, 也可使用通配符(*)配合操作
        POST address/_close
        POST address/_open
    说明事项:
    ① 使用_all或通配符操作索引, 都会受到配置文件中action.destructive_requires_name=true的限制.
    ② 关闭的索引会继续占用磁盘空间, 却又不能使用 —— 造成磁盘空间的浪费.
    ③ 可以在配置文件中禁止使用关闭索引的功能: settingscluster.indices.close.enable=false, 默认为true(开启).
```
### 9.docker安装Elasticsearch集群
[docker搭建elasticsearch集群](https://blog.csdn.net/shykevin/article/details/108354627)
[Docker 搭建elasticsearch 7.6.x集群](https://blog.csdn.net/huyande123/article/details/107449256)
[Docker下安装Elasticsearch集群（一台虚拟机三主节点）](https://blog.csdn.net/aptweasel/article/details/83410366)
```markdown
查找镜像：$ docker search elasticsearch 
拉取镜像：$ docker pull docker.elastic.co/elasticsearch/elasticsearch:7.5.2   # 拉取最新版es镜像
        -- $ docker pull docker.elastic.co/kibana/kibana:7.5.2 # 拉取最新版kibana镜像 最好和已经安装的版本一致
查看镜像库 $ docker images
宿主机创建映射目录  sudo mkdir -p /usr/local/docker/es/config/elasticsearch.yml
                 sudo mkdir -p /usr/local/docker/es/data
                 sudo mkdir -p /usr/local/docker/es/plugins
                 sudo mkdir -p /usr/local/docker/es/logs
启动镜像：(创建容器,将数据,日志,配置文件映射到本机:(-d: 后台运行容器,-p 将容器的端口映射到本机的端口,-v 将主机目录挂载到容器的目录,-e 设置参数))
    -p 9202:9200:将容器的端口9200映射到服务器的端口9202
    $ docker run --name es-node2 -p 9202:9200 -p 9302:9300 \
      -e ES_JAVA_OPTS="-Xms256m -Xmx256m" \
      -v /usr/local/docker/es/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
      -d 929d271f1798(es镜像id)
关闭容器 $ docker container stop es-node2
启动mysql容器 $ docker start es-node2  【可能不需要下面的操作也可以远程连接】【防火墙端口号必须打开】
关闭msyql容器 $ docker container stop es-node2
$ docker container ls # 查看容器信息
$ docker container logs # 获取容器的输出信息
$ docker exec -it 容器id bash # 进入容器，在其中exit也不会导致容器停止
$ docker container rm 容器名 # 删除一个处于终止状态的容器
$ docker container ls -a # 查看所有已经创建的包括终止状态的容器
$ docker container prune  # 清理掉所有处于终止状态的容器
```
### 10.使用Docker来搭建一套ELK日志分析系统
[使用Docker来搭建一套ELK日志分析系统](https://www.cnblogs.com/spec-dog/p/11489838.html)

## Java操作ES
### Spring Boot对ES增删改查和索引操作
[**Spring Boot 教程 - Elasticsearch**](https://www.cnblogs.com/Butterfly-Tri/p/13081498.html)
[**spring-boot-elasticsearch代码地址**](https://gitee.com/Butterfly-Tri/Spring-Family-Examples/tree/master/Spring-Boot/spring-boot-elasticsearch)
[「Elasticsearch」SpringBoot快速集成ES](https://www.cnblogs.com/coderxx/p/14097303.html)
[SpringBoot整合ES进行查询](https://www.cnblogs.com/keatsCoder/p/11341835.html)
[Elasticsearch Java API 很全的整理以及架构剖析](https://www.cnblogs.com/laoqing/p/11693144.html)
[spring-boot-starter-data-elasticsearch操作](https://www.cnblogs.com/lifengdi/p/11554923.html)
```markdown
查看elk-learn中的代码
```

## ElasticStack
[随笔分类 - ElasticStack](https://www.cnblogs.com/supersnowyao/category/1236567.html)
[参考视频：《Elasticsearch核心技术与实战》](https://www.baidu.com)
[geektime-geekbang/geektime-ELK](https://github.com/geektime-geekbang/geektime-ELK)
[搞懂ELK并不是一件特别难的事（ELK）](https://www.cnblogs.com/zsql/p/13164414.html)
### 1.ElasticStack的构成
[ElasticStack学习（一）：ElasticStack介绍](https://www.cnblogs.com/supersnowyao/p/11110703.html)
![](https://img2018.cnblogs.com/blog/116014/201906/116014-20190630192131420-33492444.png)
```markdown
1、ElasticSearch对数据进行搜索、分析和存储，其是基于JSON的分布式搜索和分析引擎，专门为实现水平可扩展性、高可靠性和管理便捷性而设计的。
它的实现原理主要分为以下几个步骤：
　　　　1）首先用户将数据提交到ElasticSearch数据库中；
　　　　2）再通过分词控制器将对应的语句分词；
　　　　3）将分词结果及其权重一并存入，以备用户在搜索数据时，根据权重将结果排名和打分，将返回结果呈现给用户；
2、Kibana实现数据可视化，其作用就是在ElasticSearch中进行命令行。Kibana能够以图表的形式呈现数据，并且具有可扩展的用户界面，可以全方位的配置和管理ElasticSearch。
　　　　Kibana最早的时候是基于Logstash创建的工具，后被Elastic公司在2013年收购。
　　　　1）Kibana可以提供各种可视化的图表；
　　　　2）可以通过机器学习的技术，对异常情况进行检测，用于提前发现可疑问题；
3、Beats是一个面向轻量型采集器的平台，这些采集器可以从边缘机器向Logstash、ElasticSearch发送数据，它是由Go语言进行开发的，运行效率方面比较快。
4、Logstash是动态数据收集管道，拥有可扩展的插件生态系统，支持从不同来源采集数据，转换数据，并将数据发送到不同的存储库中。其能够与ElasticSearch产生强大的协同作用，后被Elastic公司在2013年收购。
　　　　它具有如下特性：
　　　　1）实时解析和转换数据；
　　　　2）可扩展，具有200多个插件；
　　　　3）可靠性、安全性。Logstash会通过持久化队列来保证至少将运行中的事件送达一次，同时将数据进行传输加密；
　　　　4）监控；
　　　　对于日志的解决方案一般分为：日志搜索、格式化分析、全文检索、风险告警； 
5.Filebeat是用于转发和集中日志数据的轻量级传送工具。Filebeat监视您指定的日志文件或位置，收集日志事件，并将它们转发到Elasticsearch或Logstash进行索引。
    Filebeat的工作方式如下：启动Filebeat时，它将启动一个或多个输入，这些输入将在为日志数据指定的位置中查找。对于Filebeat所找到的每个日志，Filebeat都会启动收集器。
    每个收集器都读取单个日志以获取新内容，并将新日志数据发送到libbeat，libbeat将聚集事件，并将聚集的数据发送到为Filebeat配置的输出。
```
### 2.为什么要使用ELK
```markdown
日志主要包括系统日志、应用程序日志和安全日志。系统运维和开发人员可以通过日志了解服务器软硬件信息、检查配置过程中的错误及错误发生的原因。
    经常分析日志可以了解服务器的负荷，性能安全性，从而及时采取措施纠正错误。
往往单台机器的日志我们使用grep、awk等工具就能基本实现简单分析，但是当日志被分散的储存不同的设备上。
    如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。
    当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。
    集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，
    但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。
一般大型系统是一个分布式部署的架构，不同的服务模块部署在不同的服务器上，问题出现时，大部分情况需要根据问题暴露的关键信息，
    定位到具体的服务器和服务模块，构建一套集中式日志系统，可以提高定位问题的效率。
```
### 3.完整日志系统基本特征
```markdown
- 收集：能够采集多种来源的日志数据
- 传输：能够稳定的把日志数据解析过滤并传输到存储系统
- 存储：存储日志数据
- 分析：支持 UI 分析
- 警告：能够提供错误报告，监控机制
```
### 4.ELK架构分析
```markdown
1、beats+elasticsearch+kibana模式
    [一篇文章搞懂filebeat（ELK）](https://www.cnblogs.com/zsql/p/13137833.html)
    ELK框架由beats（日志分析通常使用filebeat）+elasticsearch+kibana构成，框架比较简单，入门级的框架。其中filebeat也能通过module对日志进行简单的解析和索引。并查看预建的Kibana仪表板。
    该框架适合简单的日志数据，一般可以用来玩玩，生产环境建议接入logstash
2、beats+logstash+elasticsearch+kibana模式
    [从0到1学会logstash的玩法（ELK）](https://www.cnblogs.com/zsql/p/13143445.html)
    该框架是在上面的框架的基础上引入了logstash，引入logstash带来的好处如下：
        通Logstash具有基于磁盘的自适应缓冲系统，该系统将吸收传入的吞吐量，从而减轻背压
        从其他数据源（例如数据库，S3或消息传递队列）中提取
        将数据发送到多个目的地，例如S3，HDFS或写入文件
        使用条件数据流逻辑组成更复杂的处理管道
    filebeat结合logstash带来的优势：
        1、水平可扩展性，高可用性和可变负载处理：filebeat和logstash可以实现节点之间的负载均衡，多个logstash可以实现logstash的高可用
        2、消息持久性与至少一次交付保证：使用Filebeat或Winlogbeat进行日志收集时，可以保证至少一次交付。
    从Filebeat或Winlogbeat到Logstash以及从Logstash到Elasticsearch的两种通信协议都是同步的，并且支持确认。Logstash持久队列提供跨节点故障的保护。对于Logstash中的磁盘级弹性，确保磁盘冗余非常重要。
        3、具有身份验证和有线加密的端到端安全传输：从Beats到Logstash以及从 Logstash到Elasticsearch的传输都可以使用加密方式传递 。
    与Elasticsearch进行通讯时，有很多安全选项，包括基本身份验证，TLS，PKI，LDAP，AD和其他自定义领域。
3、beats+缓存/消息队列+logstash+elasticsearch+kibana模式
    在如上的基础上我们可以在beats和logstash中间添加一些组件redis、kafka、RabbitMQ等，添加中间件将会有如下好处：
    第一，降低对日志所在机器的影响，这些机器上一般都部署着反向代理或应用服务，本身负载就很重了，所以尽可能的在这些机器上少做事；
    第二，如果有很多台机器需要做日志收集，那么让每台机器都向Elasticsearch持续写入数据，必然会对Elasticsearch造成压力，因此需要对数据进行缓冲，同时，这样的缓冲也可以一定程度的保护数据不丢失；
    第三，将日志数据的格式化与处理放到Indexer中统一做，可以在一处修改代码、部署，避免需要到多台机器上去修改配置
```


## ES面试题
### （1）es的分布式架构原理能说一下么（es是如何实现分布式的啊）？
```markdown
Elasticsearch设计的理念就是分布式搜索引擎，底层其实还是基于lucene的。
核心思想就是在多台机器上启动多个es进程实例，组成了一个es集群。
es中存储数据的基本单位是索引，比如说你现在要在es中存储一些订单数据，你就应该在es中创建一个索引，order_idx，所有的订单数据就都写到这个索引里面去，一个索引差不多就是相当于是mysql里的一张表。index -> type -> mapping -> document -> field。
	index：mysql里的一张表
	type：没法跟mysql里去对比，一个index里可以有多个type，每个type的字段都是差不多的，但是有一些略微的差别。
好比说，有一个index，是订单index，里面专门是放订单数据的。就好比说你在mysql中建表，有些订单是实物商品的订单，就好比说一件衣服，一双鞋子；有些订单是虚拟商品的订单，就好比说游戏点卡，话费充值。就两种订单大部分字段是一样的，但是少部分字段可能有略微的一些差别。
所以就会在订单index里，建两个type，一个是实物商品订单type，一个是虚拟商品订单type，这两个type大部分字段是一样的，少部分字段是不一样的。
很多情况下，一个index里可能就一个type，但是确实如果说是一个index里有多个type的情况，你可以认为index是一个类别的表，具体的每个type代表了具体的一个mysql中的表
每个type有一个mapping，如果你认为一个type是一个具体的一个表，index代表了多个type的同属于的一个类型，mapping就是这个type的表结构定义，你在mysql中创建一个表，肯定是要定义表结构的，里面有哪些字段，每个字段是什么类型。。。
mapping就代表了这个type的表结构的定义，定义了这个type中每个字段名称，字段是什么类型的，然后还有这个字段的各种配置
实际上你往index里的一个type里面写的一条数据，叫做一条document，一条document就代表了mysql中某个表里的一行给，每个document有多个field，每个field就代表了这个document中的一个字段的值
接着你搞一个索引，这个索引可以拆分成多个shard，每个shard存储部分数据。
接着就是这个shard的数据实际是有多个备份，就是说每个shard都有一个primary shard，负责写入数据，但是还有几个replica shard。primary shard写入数据之后，会将数据同步到其他几个replica shard上去。
通过这个replica的方案，每个shard的数据都有多个备份，如果某个机器宕机了，没关系啊，还有别的数据副本在别的机器上呢。高可用了吧。
es集群多个节点，会自动选举一个节点为master节点，这个master节点其实就是干一些管理的工作的，比如维护索引元数据拉，负责切换primary shard和replica shard身份拉，之类的。
要是master节点宕机了，那么会重新选举一个节点为master节点。
如果是非master节点宕机了，那么会由master节点，让那个宕机节点上的primary shard的身份转移到其他机器上的replica shard。急着你要是修复了那个宕机机器，重启了之后，master节点会控制将缺失的replica shard分配过去，同步后续修改的数据之类的，让集群恢复正常。
其实上述就是elasticsearch作为一个分布式搜索引擎最基本的一个架构设计
```
### （2）es写入数据的工作原理是什么啊？es查询数据的工作原理是什么啊？
![01_es读写底层原理剖析](E:\PBJPlus\3-Java工程师面试突击第1季（重新定义Java面试）中华石衫\15_分布式搜索引擎写入和查询的工作流程是什么样的？\01_es读写底层原理剖析.png)
```markdown
（1）es写数据过程
    1）客户端选择一个node发送请求过去，这个node就是coordinating node（协调节点）
    2）coordinating node，对document进行路由，将请求转发给对应的node（有primary shard）
    3）实际的node上的primary shard处理请求，然后将数据同步到replica node
    4）coordinating node，如果发现primary node和所有replica node都搞定之后，就返回响应结果给客户端
（2）es读数据过程
查询，GET某一条数据，写入了某个document，这个document会自动给你分配一个全局唯一的id，doc id，同时也是根据doc id进行hash路由到对应的primary shard上面去。也可以手动指定doc id，比如用订单id，用户id。
你可以通过doc id来查询，会根据doc id进行hash，判断出来当时把doc id分配到了哪个shard上面去，从那个shard去查询
    1）客户端发送请求到任意一个node，成为coordinate node
    2）coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡
    3）接收请求的node返回document给coordinate node
    4）coordinate node返回document给客户端
（3）es搜索数据过程
es最强大的是做全文检索，就是比如你有三条数据
java真好玩儿啊
java好难学啊
j2ee特别牛
你根据java关键词来搜索，将包含java的document给搜索出来
es就会给你返回：java真好玩儿啊，java好难学啊
    1）客户端发送请求到一个coordinate node
    2）协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard也可以
    3）query phase：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果
    4）fetch phase：接着由协调节点，根据doc id去各个节点上拉取实际的document数据，最终返回给客户端
（4）搜索的底层原理，倒排索引，画图说明传统数据库和倒排索引的区别
（5）写数据底层原理
    1）先写入buffer，在buffer里的时候数据是搜索不到的；同时将数据写入translog日志文件
    2）如果buffer快满了，或者到一定时间，就会将buffer数据refresh到一个新的segment file中，但是此时数据不是直接进入segment file的磁盘文件的，而是先进入os cache的。这个过程就是refresh。
每隔1秒钟，es将buffer中的数据写入一个新的segment file，每秒钟会产生一个新的磁盘文件，segment file，这个segment file中就存储最近1秒内buffer中写入的数据
但是如果buffer里面此时没有数据，那当然不会执行refresh操作咯，每秒创建换一个空的segment file，如果buffer里面有数据，默认1秒钟执行一次refresh操作，刷入一个新的segment file中
操作系统里面，磁盘文件其实都有一个东西，叫做os cache，操作系统缓存，就是说数据写入磁盘文件之前，会先进入os cache，先进入操作系统级别的一个内存缓存中去
只要buffer中的数据被refresh操作，刷入os cache中，就代表这个数据就可以被搜索到了
为什么叫es是准实时的？NRT，near real-time，准实时。默认是每隔1秒refresh一次的，所以es是准实时的，因为写入的数据1秒之后才能被看到。
可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。
只要数据被输入os cache中，buffer就会被清空了，因为不需要保留buffer了，数据在translog里面已经持久化到磁盘去一份了
3）只要数据进入os cache，此时就可以让这个segment file的数据对外提供搜索了
4）重复1~3步骤，新的数据不断进入buffer和translog，不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。随着这个过程推进，translog会变得越来越大。当translog达到一定长度的时候，就会触发commit操作。
buffer中的数据，倒是好，每隔1秒就被刷到os cache中去，然后这个buffer就被清空了。所以说这个buffer的数据始终是可以保持住不会填满es进程的内存的。
每次一条数据写入buffer，同时会写入一条日志到translog日志文件中去，所以这个translog日志文件是不断变大的，当translog日志文件大到一定程度的时候，就会执行commit操作。
5）commit操作发生第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer
6）将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有segment file
7）强行将os cache中目前所有的数据都fsync到磁盘文件中去
translog日志文件的作用是什么？就是在你执行commit操作之前，数据要么是停留在buffer中，要么是停留在os cache中，无论是buffer还是os cache都是内存，一旦这台机器死了，内存中的数据就全丢了。
所以需要将数据对应的操作写入一个专门的日志文件，translog日志文件中，一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。
commit操作：1、写commit point；2、将os cache数据fsync强刷到磁盘上去；3、清空translog日志文件
8）将现有的translog清空，然后再次重启启用一个translog，此时commit操作完成。默认每隔30分钟会自动执行一次commit，但是如果translog过大，也会触发commit。整个commit的过程，叫做flush操作。我们可以手动执行flush操作，就是将所有os cache数据刷到磁盘文件中去。
不叫做commit操作，flush操作。es中的flush操作，就对应着commit的全过程。我们也可以通过es api，手动执行flush操作，手动将os cache中的数据fsync强刷到磁盘上去，记录一个commit point，清空translog日志文件。
9）translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以默认情况下，可能有5秒的数据会仅仅停留在buffer或者translog文件的os cache中，如果此时机器挂了，会丢失5秒钟的数据。但是这样性能比较好，最多丢5秒的数据。也可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。
实际上你在这里，如果面试官没有问你es丢数据的问题，你可以在这里给面试官炫一把，你说，其实es第一是准实时的，数据写入1秒后可以搜索到；可能会丢失数据的，你的数据有5秒的数据，停留在buffer、translog os cache、segment file os cache中，有5秒的数据不在磁盘上，此时如果宕机，会导致5秒的数据丢失。
如果你希望一定不能丢失数据的话，你可以设置个参数，官方文档，百度一下。每次写入一条数据，都是写入buffer，同时写入磁盘上的translog，但是这会导致写性能、写入吞吐量会下降一个数量级。本来一秒钟可以写2000条，现在你一秒钟只能写200条，都有可能。
10）如果是删除操作，commit的时候会生成一个.del文件，里面将某个doc标识为deleted状态，那么搜索的时候根据.del文件就知道这个doc被删除了
11）如果是更新操作，就是将原来的doc标识为deleted状态，然后新写入一条数据
12）buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，此时会定期执行merge
13）每次merge的时候，会将多个segment file合并成一个，同时这里会将标识为deleted的doc给物理删除掉，然后将新的segment file写入磁盘，这里会写一个commit point，标识所有新的segment file，然后打开segment file供搜索使用，同时删除旧的segment file。
es里的写流程，有4个底层的核心概念，refresh、flush、translog、merge
当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file。
```
### （3）es在数据量很大的情况下（数十亿级别）如何提高查询性能啊？
![01_filesystem cache对es性能的影响](E:\PBJPlus\3-Java工程师面试突击第1季（重新定义Java面试）中华石衫\16_分布式搜索引擎在几十亿数据量级的场景下如何优化查询性能？\01_filesystem cache对es性能的影响.png)
```markdown
在这个海量数据的场景下，如何提升es搜索的性能，也是我们之前生产环境实践经验所得
（1）性能优化的杀手锏——filesystem cache
os cache，操作系统的缓存
你往es里写的数据，实际上都写到磁盘文件里去了，磁盘文件里的数据操作系统会自动将里面的数据缓存到os cache里面去
es的搜索引擎严重依赖于底层的filesystem cache，你如果给filesystem cache更多的内存，尽量让内存可以容纳所有的indx segment file索引数据文件，那么你搜索的时候就基本都是走内存的，性能会非常高。
性能差距可以有大，我们之前很多的测试和压测，如果走磁盘一般肯定上秒，搜索性能绝对是秒级别的，1秒，5秒，10秒。但是如果是走filesystem cache，是走纯内存的，那么一般来说性能比走磁盘要高一个数量级，基本上就是毫秒级的，从几毫秒到几百毫秒不等。
之前有个学员，一直在问我，说他的搜索性能，聚合性能，倒排索引，正排索引，磁盘文件，十几秒。。。。
学员的真实案例
比如说，你，es节点有3台机器，每台机器，看起来内存很多，64G，总内存，64 * 3 = 192g
每台机器给es jvm heap是32G，那么剩下来留给filesystem cache的就是每台机器才32g，总共集群里给filesystem cache的就是32 * 3 = 96g内存
我就问他，ok，那么就是你往es集群里写入的数据有多少数据量？
如果你此时，你整个，磁盘上索引数据文件，在3台机器上，一共占用了1T的磁盘容量，你的es数据量是1t，每台机器的数据量是300g
你觉得你的性能能好吗？filesystem cache的内存才100g，十分之一的数据可以放内存，其他的都在磁盘，然后你执行搜索操作，大部分操作都是走磁盘，性能肯定差
当时他们的情况就是这样子，es在测试，弄了3台机器，自己觉得还不错，64G内存的物理机。自以为可以容纳1T的数据量。
归根结底，你要让es性能要好，最佳的情况下，就是你的机器的内存，至少可以容纳你的总数据量的一半
比如说，你一共要在es中存储1T的数据，那么你的多台机器留个filesystem cache的内存加起来综合，至少要到512G，至少半数的情况下，搜索是走内存的，性能一般可以到几秒钟，2秒，3秒，5秒
如果最佳的情况下，我们自己的生产环境实践经验，所以说我们当时的策略，是仅仅在es中就存少量的数据，就是你要用来搜索的那些索引，内存留给filesystem cache的，就100G，那么你就控制在100gb以内，相当于是，你的数据几乎全部走内存来搜索，性能非常之高，一般可以在1秒以内
比如说你现在有一行数据
id name age ....30个字段
但是你现在搜索，只需要根据id name age三个字段来搜索
如果你傻乎乎的往es里写入一行数据所有的字段，就会导致说70%的数据是不用来搜索的，结果硬是占据了es机器上的filesystem cache的空间，单挑数据的数据量越大，就会导致filesystem cahce能缓存的数据就越少
**仅仅只是写入es中要用来检索的少数几个字段就可以了，比如说，就写入es id name age三个字段就可以了，然后你可以把其他的字段数据存在mysql里面，我们一般是建议用es + hbase的这么一个架构。
hbase的特点是适用于海量数据的在线存储，就是对hbase可以写入海量数据，不要做复杂的搜索，就是做很简单的一些根据id或者范围进行查询的这么一个操作就可以了
从es中根据name和age去搜索，拿到的结果可能就20个doc id，然后根据doc id到hbase里去查询每个doc id对应的完整的数据，给查出来，再返回给前端。
你最好是写入es的数据小于等于，或者是略微大于es的filesystem cache的内存容量
然后你从es检索可能就花费20ms，然后再根据es返回的id去hbase里查询，查20条数据，可能也就耗费个30ms，可能你原来那么玩儿，1T数据都放es，会每次查询都是5~10秒，现在可能性能就会很高，每次查询就是50ms。
elastcisearch减少数据量仅仅放要用于搜索的几个关键字段即可，尽量写入es的数据量跟es机器的filesystem cache是差不多的就可以了；其他不用来检索的数据放hbase里，或者mysql。
所以之前有些学员也是问，我也是跟他们说，尽量在es里，就存储必须用来搜索的数据，比如说你现在有一份数据，有100个字段，其实用来搜索的只有10个字段，建议是将10个字段的数据，存入es，剩下90个字段的数据，可以放mysql，hadoop hbase，都可以
这样的话，es数据量很少，10个字段的数据，都可以放内存，就用来搜索，搜索出来一些id，通过id去mysql，hbase里面去查询明细的数据
（2）数据预热

假如说，哪怕是你就按照上述的方案去做了，es集群中每个机器写入的数据量还是超过了filesystem cache一倍，比如说你写入一台机器60g数据，结果filesystem cache就30g，还是有30g数据留在了磁盘上。 

举个例子，就比如说，微博，你可以把一些大v，平时看的人很多的数据给提前你自己后台搞个系统，每隔一会儿，你自己的后台系统去搜索一下热数据，刷到filesystem cache里去，后面用户实际上来看这个热数据的时候，他们就是直接从内存里搜索了，很快。

电商，你可以将平时查看最多的一些商品，比如说iphone 8，热数据提前后台搞个程序，每隔1分钟自己主动访问一次，刷到filesystem cache里去。

对于那些你觉得比较热的，经常会有人访问的数据，最好做一个专门的缓存预热子系统，就是对热数据，每隔一段时间，你就提前访问一下，让数据进入filesystem cache里面去。这样期待下次别人访问的时候，一定性能会好一些。

（3）冷热分离


关于es性能优化，数据拆分，我之前说将大量不搜索的字段，拆分到别的存储中去，这个就是类似于后面我最后要讲的mysql分库分表的垂直拆分。

es可以做类似于mysql的水平拆分，就是说将大量的访问很少，频率很低的数据，单独写一个索引，然后将访问很频繁的热数据单独写一个索引

你最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在filesystem os cache里，别让冷数据给冲刷掉。

你看，假设你有6台机器，2个索引，一个放冷数据，一个放热数据，每个索引3个shard

3台机器放热数据index；另外3台机器放冷数据index

然后这样的话，你大量的时候是在访问热数据index，热数据可能就占总数据量的10%，此时数据量很少，几乎全都保留在filesystem cache里面了，就可以确保热数据的访问性能是很高的。

但是对于冷数据而言，是在别的index里的，跟热数据index都不再相同的机器上，大家互相之间都没什么联系了。如果有人访问冷数据，可能大量数据是在磁盘上的，此时性能差点，就10%的人去访问冷数据；90%的人在访问热数据。

（4）document模型设计

有不少同学问我，mysql，有两张表

订单表：id order_code total_price

1 测试订单 5000

订单条目表：id order_id goods_id purchase_count price

1 1 1 2 2000
2 1 2 5 200

我在mysql里，都是select * from order join order_item on order.id=order_item.order_id where order.id=1

1 测试订单 5000 1 1 1 2 2000
1 测试订单 5000 2 1 2 5 200

在es里该怎么玩儿，es里面的复杂的关联查询，复杂的查询语法，尽量别用，一旦用了性能一般都不太好

设计es里的数据模型

写入es的时候，搞成两个索引，order索引，orderItem索引

order索引，里面就包含id order_code total_price
orderItem索引，里面写入进去的时候，就完成join操作，id order_code total_price id order_id goods_id purchase_count price

写入es的java系统里，就完成关联，将关联好的数据直接写入es中，搜索的时候，就不需要利用es的搜索语法去完成join来搜索了

document模型设计是非常重要的，很多操作，不要在搜索的时候才想去执行各种复杂的乱七八糟的操作。es能支持的操作就是那么多，不要考虑用es做一些它不好操作的事情。如果真的有那种操作，尽量在document模型设计的时候，写入的时候就完成。另外对于一些太复杂的操作，比如join，nested，parent-child搜索都要尽量避免，性能都很差的。

很多同学在问我，很多复杂的乱七八糟的一些操作，如何执行

两个思路，在搜索/查询的时候，要执行一些业务强相关的特别复杂的操作：

1）在写入数据的时候，就设计好模型，加几个字段，把处理好的数据写入加的字段里面
2）自己用java程序封装，es能做的，用es来做，搜索出来的数据，在java程序里面去做，比如说我们，基于es，用java封装一些特别复杂的操作

（5）分页性能优化

es的分页是较坑的，为啥呢？举个例子吧，假如你每页是10条数据，你现在要查询第100页，实际上是会把每个shard上存储的前1000条数据都查到一个协调节点上，如果你有个5个shard，那么就有5000条数据，接着协调节点对这5000条数据进行一些合并、处理，再获取到最终第100页的10条数据。

分布式的，你要查第100页的10条数据，你是不可能说从5个shard，每个shard就查2条数据？最后到协调节点合并成10条数据？你必须得从每个shard都查1000条数据过来，然后根据你的需求进行排序、筛选等等操作，最后再次分页，拿到里面第100页的数据。

你翻页的时候，翻的越深，每个shard返回的数据就越多，而且协调节点处理的时间越长。非常坑爹。所以用es做分页的时候，你会发现越翻到后面，就越是慢。

我们之前也是遇到过这个问题，用es作分页，前几页就几十毫秒，翻到10页之后，几十页的时候，基本上就要5~10秒才能查出来一页数据了

1）不允许深度分页/默认深度分页性能很惨

你系统不允许他翻那么深的页，pm，默认翻的越深，性能就越差

2）类似于app里的推荐商品不断下拉出来一页一页的

类似于微博中，下拉刷微博，刷出来一页一页的，你可以用scroll api，自己百度

scroll会一次性给你生成所有数据的一个快照，然后每次翻页就是通过游标移动，获取下一页下一页这样子，性能会比上面说的那种分页性能也高很多很多

针对这个问题，你可以考虑用scroll来进行处理，scroll的原理实际上是保留一个数据快照，然后在一定时间内，你如果不断的滑动往后翻页的时候，类似于你现在在浏览微博，不断往下刷新翻页。那么就用scroll不断通过游标获取下一页数据，这个性能是很高的，比es实际翻页要好的多的多。
但是唯一的一点就是，这个适合于那种类似微博下拉翻页的，不能随意跳到任何一页的场景。同时这个scroll是要保留一段时间内的数据快照的，你需要确保用户不会持续不断翻页翻几个小时。
无论翻多少页，性能基本上都是毫秒级的
因为scroll api是只能一页一页往后翻的，是不能说，先进入第10页，然后去120页，回到58页，不能随意乱跳页。所以现在很多产品，都是不允许你随意翻页的，app，也有一些网站，做的就是你只能往下拉，一页一页的翻
```
### （4）es生产集群的部署架构是什么？每个索引的数据量大概有多少？每个索引大概有多少个分片？
```markdown
其实这个问题没啥，如果你确实干过es，那你肯定了解你们生产es集群的实际情况，部署了几台机器？有多少个索引？每个索引有多大数据量？每个索引给了多少个分片？你肯定知道！
但是如果你确实没干过，也别虚，我给你说一个基本的版本，你到时候就简单说一下就好了
（1）es生产集群我们部署了5台机器，每台机器是6核64G的，集群总内存是320G
（2）我们es集群的日增量数据大概是2000万条，每天日增量数据大概是500MB，每月增量数据大概是6亿，15G。
    目前系统已经运行了几个月，现在es集群里数据总量大概是100G左右。
（3）目前线上有5个索引（这个结合你们自己业务来，看看自己有哪些数据可以放es的），每个索引的数据量大概是20G，所以这个数据量之内，
    我们每个索引分配的是8个shard，比默认的5个shard多了3个shard。
```
### （5）ES 深入
```markdown
消息队列，kafka，复制的底层原理，leader选举的算法，增加partition以后的rebalance算法，扣很多很多的细节，如何优化kafka写入的吞吐量
其实这块如果挖深了可以问的极其深，如果是我来深挖，可能会挖到es底层的相关度评分算法（TF/IDF算法）、
deep paging、上千万数据批处理、跨机房多集群同步、搜索效果优化，等等吧，很多的实际生产问题。
```
###
##
