# 计算机组成原理和硬件知识学习
[极客时间：深入浅出计算机组成原理](https://www.baidu.com)

[TOC]


## 三、计算机组成原理
### [计算机组成原理](https://www.cnblogs.com/reminis/p/12896053.html)
### [【重学计算机】计算机组成原理](https://www.cnblogs.com/flashsun/p/10628433.html)
### [随笔分类 - 重学计算机笔记](https://www.cnblogs.com/flashsun/category/1391951.html)
[一口气看完45个寄存器，CPU核心技术大揭秘](https://www.cnblogs.com/xuanyuan/p/13850548.html)
[你不知道的内存知识](https://www.cnblogs.com/jiagoujishu/p/13850552.html)
>> [程序员cxuan:computer-basic.pdf]()
>> [全网最硬核讲解计算机启动流程](https://www.cnblogs.com/flashsun/p/13942138.html)
### 1.CPU
[10 张图打开 CPU 缓存一致性的大门](https://www.cnblogs.com/xiaolincoding/p/13886559.html)
[如何写出让 CPU 跑得更快的代码？](https://www.cnblogs.com/xiaolincoding/p/13836230.html)
```markdown
CPU的核心是从程序或者应用程序获取指令并且执行计算。此过程可以分成三个关键阶段：提取、解码、执行。
    CPU从系统的RAM中提取指令，然后解码该指令的实际内容，然后再由CPU的相关部分执行该指令。     
RAM:随机读取存储器，也叫主存，是与CPU直接交换数据的内部存储器。它可以随时读写（刷新时除外），速度快，通常作为操作系统或其他正在运行的查询的临时数据存储介质。
CPU主要由两个部分组成：控制单元和算术逻辑单元（ALU）
    控制单元：从内存中提取指令并解码执行
    算术逻辑单元：处理算术和逻辑运算
从功能来看：CPU的内部由寄存器、控制器、运算器和时钟四个部分组成，各个部分之间通过电信号连通。
    寄存器：是中央处理器内的组成部分。它们可以用来暂存指令、数据和地址。可以看成内存的一种。
    控制器：负责吧内存上的指令、数据读入寄存器，并根据指令的结果控制计算机
    运算器：负责运算从内存中读入寄存器的数据
    时钟：负责发出CPU开始计时的时钟信号
寄存器分类：累加寄存器、标志寄存器、程序计数器、基址寄存器、变址寄存器、通用寄存器、指令寄存器、栈寄存器。
    累加寄存器：存储运行的数据和运算之后的数据。
    标志寄存器：用于反应处理器的状态和运算结果的某些特征以及控制指令的执行。比方说跳转指令。
    程序寄存器（PC寄存器/指令寄存器）：用于存放下一条指令所在单元的地址的地方。
    基址寄存器：存储数据内存的起始位置。
    变址寄存器：存储基址寄存器的相对地址。
    通用寄存器：存储任意数据。
    指令寄存器：存储正在被运行的指令，CPU内部使用，程序员无法对该寄存器进行读写。
    栈寄存器：存储渣区域的起始位置。
累加寄存器、标志寄存器、程序计数器、基址寄存器和指令寄存器都只有一个，其他寄存器一般有多个。
CPU指令执行过程：取指令、指令译码、执行指令、访存去数、结果写回。
```
### 2.内存
```markdown
内存：内存是程序与CPU进行沟通的桥梁，计算机所有程序的运行都是在内存中运行的，内存又被称为主存。
    其作用是存放CPU中的运算数据，以及与硬盘等外部存储设备交换的数据。
存储器分类：
    随机存储器（RAM）：内存中最重要的一种，表示既可以从中读取数据也可以写入数据。当机器关闭时，内存中的信息会丢失。
    只读存储器（ROM）：ROM一般只能用于数据的读取，不能写入数据，但是当机器停电时，这些数据不会丢失。
    高速缓存（Cache）：分为一级缓存、二级缓存、三级缓存。位于内存和CPU之间是一个读写速度比内存更快的存储器。
```
### 3.压缩算法
```markdown
RLE算法：把重复数据用数据*重复次数来表示的形式的压缩方法。常用于压缩传真的图像等等。缺点：只能由于特定序列的数据有效果。
哈夫曼算法和莫尔斯编码：
    哈夫曼算法的关键：在于多次出现的数据小于8位的字节数表示，不常用的数据则可以使用超过8位的字节数表示。
    莫尔斯编码：是根据日常文本中各字符的出现频率来决定表示个字符的编码数据长度的。
可逆压缩和非可逆压缩：
    可逆压缩：能还原到压缩前状态的压缩。
    非可逆压缩：无法还原到压缩前状态的压缩。
```
### 4.磁盘
```markdown
磁盘和内存都具有存储功能，都属于存储设备。区别在于，内存是通过电流来实现存储；磁盘是通过磁记录技术来实现存储。
    断电后内存中非数据汇丢失，但是磁盘中的数据可以长久保留。
    内存属于内部存储设备，硬盘属于外部存储设备。磁盘中存储的出现必须加装到内存中才能运行。
    磁盘的物理结构：指的是磁盘存储数据的形式。可分为可变长方式和扇区方式。
虚拟内存：是内存和磁盘交互的第二媒介，就是把磁盘的一部分当成内存来使用。
    虚拟内存的方法欧分页式和分段式两种，Windows采用非是分页式。页的大小为4KB
```
### 计算机体系结构
![image-20201119170846294](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201119170853.png)
### 冯·诺依曼体系结构：计算机组成的金字塔
![image-20201121152957307](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201121152957.png)
```markdown
CPU、内存、主板、输入输出设备、硬盘
鼠标、键盘以及硬盘，这些都是插在主板上的。作为外部I/O设备，它们是通过主板上的南桥（SouthBridge）芯片组，来控制和CPU之间的通信的。
“南桥”芯片的名字很直观，一方面，它在主板上的位置，通常在主板的“南面”。另一方面，它的作用就是作为“桥”，来连接鼠标、键盘以及硬盘这些外部设备和CPU之间的通信。
    算术逻辑单元（Arithmetic Logic Unit，ALU）和处理器寄存器（Processor Register）的处理器单元（Processing Unit），用来完成各种算术和逻辑运算。
    指令寄存器（Instruction Reigster）和程序计数器（Program Counter）的控制器单元（Control Unit/CU），用来控制程序的流程，通常就是不同条件下的分支和跳转。
    在现在的计算机里，上面的算术逻辑单元和这里的控制器单元，共同组成了我们说的 CPU。
    用来存储数据（Data）和指令（Instruction）的内存。以及更大容量的外部存储。
    各种输入和输出设备，以及对应的输入和输出机制。
任何一台计算机的任何一个部件都可以归到运算器、控制器、存储器、输入设备和输出设备中，而所有的现代计算机也都是基于这个基础架构来设计开发的。
学习组成原理，其实就是学习控制器、运算器的工作原理，也就是CPU是怎么工作的，以及为何这样设计；
    学习内存的工作原理，从最基本的电路，到上层抽象给到CPU乃至应用程序的接口是怎样的；
    学习CPU是怎么和输入设备、输出设备打交道的。
学习组成原理，就是在理解从控制器、运算器、存储器、输入设备以及输出设备，从电路这样的硬件，到最终开放给软件的接口，是怎么运作的，为什么要设计成这样，以及在软件开发层面怎么尽可能用好它。
```
### 计算机组成原理的学习框架
![image-20201119190731355](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201119190731.png)
```markdown
总结了三个学习方法，帮你更好地掌握这些知识点，并且能够学为所用，让你在工作中能够用得上。
    - 学会提问自己来串联知识点。学完一个知识点之后，你可以从下面两个方面，问一下自己。
        我写的程序，是怎样从输入的代码，变成运行的程序，并得到最终结果的？
        整个过程中，计算器层面到底经历了哪些步骤，有哪些地方是可以优化的？
    - 写一些示例程序来验证知识点。通过把对应的知识点，变成一个个性能对比的示例代码程序记录下来，是把这些知识点融汇贯通的好方法。
    - 通过和计算机硬件发展的历史做对照。
        过了解充满戏剧性和故事性的计算机硬件发展史，让你更容易理解计算机组成中各种原理的由来。
        奔腾4和SPARC的失败，以及ARM的成功，能让我们记住CPU指令集的繁与简、权衡性能和功耗的重要性，而现今高速发展的机器学习和边缘计算，又给计算机硬件设计带来了新的挑战。   
```
### 计算机性能
```markdown
1.响应时间（Response time）或者叫执行时间（Execution time），想要提升响应时间这个性能指标，你可以理解为让计算机“跑得更快”。
    响应时间指的就是，我们执行一个程序，到底需要花多少时间。花的时间越少，自然性能就越好。
2.吞吐率（Throughput）或者带宽（Bandwidth），想要提升这个指标，你可以理解为让计算机“搬得更多”。  
    在一定的时间范围内，到底能处理多少事情。这里的“事情”，在计算机里就是处理的数据或者执行的程序指令。
3.Linux下有一个叫time的命令，可以帮我们统计出来，同样的Wall Clock Time下，程序实际在CPU上到底花了多少时间。
    $ time seq 1000000 | wc -l
    1000000
    real  0m0.101s   # real time，也就是我们说的Wall Clock Time，也就是运行程序整个过程中流逝掉的时间；
    user  0m0.031s   # user time，也就是CPU在运行你的程序，在用户态运行指令的时间；
    sys   0m0.016s   # sys time，是CPU在运行你的程序，在操作系统内核里运行指令的时间。
    程序实际花费的 CPU 执行时间（CPU Time），就是 user time 加上 sys time。
    除了 CPU 之外，时间这个性能指标还会受到主板、内存这些其他相关硬件的影响。
4.程序的CPU执行时间 =CPU时钟周期数×时钟周期时间
    CPU的主频：2.8GHz，我们可以先粗浅地认为，CPU在1秒时间内，可以执行的简单指令的数量是2.8G条。
    最简单的提升性能方案，自然缩短时钟周期时间，也就是提升主频。
    CPU 时钟周期数 = 指令数×每条指令的平均时钟周期数（Cycles Per Instruction，简称 CPI）
    程序的 CPU 执行时间 = 指令数×CPI×Clock Cycle Time
5.想要解决性能问题，其实就是要优化这三者。
    - 时钟周期时间，就是计算机主频，这个取决于计算机硬件。我们所熟知的摩尔定律就一直在不停地提高我们计算机的主频。
    比如说，我最早使用的80386主频只有33MHz，现在手头的笔记本电脑就有2.9GHz，在主频层面，就提升了将近100倍。
    - 每条指令的平均时钟周期数CPI，就是一条指令到底需要多少CPU Cycle。
    现代的CPU通过流水线技术（Pipeline），让一条指令需要的CPU Cycle尽可能地少。因此，对于CPI的优化，也是计算机组成和体系结构中的重要一环。
    - 指令数，代表执行我们的程序到底需要多少条指令、用哪些指令。这个很多时候就把挑战交给了编译器。同样的代码，编译成计算机指令时候，就有各种不同的表示方式。
```
### 计算机功耗
```markdown
在CPU里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。
一个CPU的功率，可以用这样一个公式来表示：
    功耗 ~= 1/2 ×负载电容×电压的平方×开关频率×晶体管数量
为了要提升性能，我们需要不断地增加晶体管数量。同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点。
这个就是平时我们所说的提升“制程”。从28nm到7nm，相当于晶体管本身变成了原来的1/4大小。
阿姆达尔定律（Amdahl’s Law）。这个定律说的就是，对于一个程序进行优化之后，处理器并行运算之后效率提升的情况。
    具体可以用这样一个公式来表示：
        优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间
三种常见的性能提升思路，分别是，加速大概率事件、通过流水线提高性能和通过预测提高性能。
```
### 机器码&计算机指令
```markdown
平时编写的代码，到底是怎么变成一条条计算机指令，最后被CPU执行的呢
    // test.c
    int main()
    {
      int a = 1; 
      int b = 2;
      a = a + b;
    }
在一个Linux操作系统上，我们可以简单地使用gcc和objdump这样两条命令，把对应的汇编代码和机器码都打印出来。
    $ gcc -g -c test.c
    $ objdump -d -M intel -S test.o
指令分类：
    第一类是算术类指令。我们的加减乘除，在CPU层面，都会变成一条条算术类指令。
    第二类是数据传输类指令。给变量赋值、在内存里读写数据，用的都是数据传输类指令。
    第三类是逻辑类指令。逻辑上的与或非，都是这一类指令。
    第四类是条件分支类指令。日常我们写的“if/else”，其实都是条件分支类指令。
    最后一类是无条件跳转指令。写一些大一点的程序，我们常常需要写一些函数或者方法。在调用函数的时候，其实就是发起了一个无条件跳转指令。
为什么我们需要程序栈？
    函数编译之后，代码先执行了一条push指令和一条mov指令；在函数执行结束的时候，又执行了一条pop和一条ret指令。
    这四条指令的执行，其实就是在进行压栈（Push）和出栈（Pop）操作。
C语言文件执行的过程
    C 语言代码 - 汇编代码 - 机器码  这个过程，在我们的计算机上进行的时候是由两部分组成的。
    第一个部分由编译（Compile）、汇编（Assemble）以及链接（Link）三个阶段组成。在这三个阶段完成之后，我们就生成了一个可执行文件。
    第二部分，我们通过装载器（Loader）把可执行文件装载（Load）到内存中。CPU从内存中读取指令和数据，来开始真正执行程序。
ELF其实是一种文件格式的标准，ELF文件有三类:可重定向文件、可执行文件、共享目标文件。
    代码经过预处理、编译、汇编后形成可重定向文件，可重定向文件经过链接后生成可执行文件。
```
### 虚拟内存、内存交换和内存分页
````markdown
程序装载面临的挑战
    第一，可执行程序加载后占用的内存空间应该是连续的。
    第二，我们需要同时加载很多个程序，并且不能让程序自己规定在内存中加载的位置。
内存分段：一段连续的物理内存和虚拟内存地址进行映射的方法。会分配一整段连续的空间给到程序。
    虚拟内存地址（Virtual Memory Address）：把指令里用到的内存地址。
    物理内存地址（Physical Memory Address）：实际在内存硬件里面的空间地址。
内存交换（Memory Swapping）：把数据写到硬盘上，然后再从硬盘上读回来到内存里面。 
内存分页（Paging）：把整个物理内存空间切成一段段固定尺寸的大小。一个连续并且尺寸固定的内存空间叫页（Page）
    从虚拟内存到物理内存的映射，不再是拿整段连续的内存的物理地址，而是按照一个一个页来的。
    页的尺寸一般远远小于整个程序的大小。在Linux下，我们通常只设置成4KB。通过命令查看$ getconf PAGE_SIZE
通过虚拟内存、内存交换和内存分页这三个技术的组合，我们最终得到了一个让程序不需要考虑实际的物理内存地址、大小和当前分配空间的解决方案。
通过引入虚拟内存、页映射和内存交换，我们的程序本身，就不再需要考虑对应的真实的内存地址、程序加载、内存管理等问题了。
任何一个程序，都只需要把内存当成是一块完整而连续的空间来直接使用。
动态链接（Dynamic Link）&静态链接（Static Link）
    在动态链接的过程中，我们想要“链接”的，不是存储在硬盘上的目标文件代码，而是加载到内存中的共享库（Shared Libraries）。
    在Windows下，这些共享库文件就是.dll文件，也就是Dynamic-Link Libary（DLL，动态链接库）。
    在Linux下，这些共享库文件就是.so文件，也就是Shared Object（也称之为动态链接库）。
相对地址（Relative Address）
    各种指令中使用到的内存地址，给出的不是一个绝对的地址空间，而是一个相对于当前指令偏移量的内存地址。
    因为整个共享库是放在一段连续的虚拟内存地址中的，无论装载到哪一段地址，不同指令之间的相对地址都是不变的。            
````
### 二进制编码
![image-20201121164250068](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201121164250.png)
```markdown

```
### 指令+计算=CPU
![image-20201121172225041](https://raw.githubusercontent.com/peng4444/picgo/main/img/20201121172225.png)
```markdown
计算机每执行一条指令的过程，可以分解成这样几个步骤:
    1.Fetch（取得指令），也就是从PC寄存器里找到对应的指令地址，根据指令地址从内存里把具体的指令，加载到指令寄存器中，然后把PC寄存器自增，好在未来执行下一条指令。
    2.Decode（指令译码），也就是根据指令寄存器里面的指令，解析成要进行什么样的操作，是R、I、J中的哪一种指令，具体要操作哪些寄存器、数据或者内存地址。
    3.Execute（执行指令），也就是实际运行对应的R、I、J这些特定的指令，进行算术逻辑操作、数据传输或者直接的地址跳转。
    4. 重复进行 1～3 的步骤。
指令周期（Instruction Cycle）:这样的步骤，其实就是一个永不停歇的“Fetch - Decode - Execute”的循环，称之为指令周期（Instruction Cycle）。
Machine Cycle，机器周期或者CPU周期:从内存里面读取一条指令的最短时间，称为CP周期。
Clock Cycle，也就是时钟周期以及我们机器的主频。
一个CPU周期，通常会由几个时钟周期累积起来。一个CPU周期的时间，就是这几个Clock Cycle的总和。
一个指令周期，包含多个CPU周期，而一个CPU周期包含多个时钟周期。
CPU运转需要的数据通路和控制器:ALU这样的组合逻辑电路、用来存储数据的锁存器和D触发器电路、用来实现PC寄存器的计数器电路，以及用来解码和寻址的译码器电路。
在单指令周期处理器里面，无论是执行一条用不到ALU的无条件跳转指令，还是一条计算起来电路特别复杂的浮点数乘法运算，我们都等要等满一个时钟周期。
通过流水线设计来提升 CPU 的吞吐率，我们需要冒哪些风险。
    分别是结构冒险（Structural Hazard）、数据冒险（Data Hazard）以及控制冒险（Control Hazard）。
    CPU内部的高速缓存分成了指令缓存（Instruction Cache）和数据缓存（Data Cache）两部分。
    通过增加资源、停顿等待以及主动转发数据的方式，来解决结构冒险和数据冒险问题。
    结构冒险和数据冒险，以及增加资源、流水线停顿、操作数前推、乱序执行，这些解决各种“冒险”的技术方案。
超标量（Superscalar）技术能够让取指令以及指令译码也并行进行；在编译的过程，超长指令字（VLIW）技术可以搞定指令先后的依赖关系，使得一次可以取一个指令包。
```
### 异常
```markdown
异常的分类：中断、陷阱、故障和中止

```
###